{"posts":[{"title":"MacOS app 已损坏，无法打开，你应该将它移到废纸篓","text":"允许任何来源12sudo spctl --master-disable# 并输入密码 绕过公证123sudo xattr -rd com.apple.quarantine /Applications xxxxxx.app# 并输入密码# xxxxxx.app 为安装的应用程序名称 给软件签名12345# 没有安装xcode的xcode-select --installsudo codesign --force --deep --sign - /Applications/xxxxxx.app# 并输入密码# xxxxxx.app 为安装的应用程序名称，注意空格","link":"/2021/03/22/MacOS%20app%E5%B7%B2%E6%8D%9F%E5%9D%8F/"},{"title":"动态代理 Dynamic Proxy","text":"静态代理原始接口和实现类1234567891011121314package vip.housir.proxy;/** * @author housirvip */public interface SmsService { /** * send msg * * @param msg String */ public void send(String msg);} 123456789101112package vip.housir.proxy;/** * @author housirvip */public class SmsServiceImpl implements SmsService { @Override public void send(String msg) { System.out.println(&quot;send msg: &quot; + msg); }} 静态代理类12345678910111213141516171819package vip.housir.proxy;/** * @author housirvip */public class SmsProxy { private final SmsService smsService; public SmsProxy(SmsService sms) { smsService = sms; } public void send(String msg) { System.out.println(&quot;Static Proxy before: send&quot;); smsService.send(msg); System.out.println(&quot;Static Proxy after: send&quot;); }} 手动调用123456789101112import org.junit.Test;import vip.housir.proxy.SmsProxy;import vip.housir.proxy.SmsServiceImpl;public class TestDynamicProxy { @Test public void testStaticProxy() { SmsProxy sms = new SmsProxy(new SmsServiceImpl()); sms.send(&quot;yes sir!&quot;); }} 结果输出12345Static Proxy before: sendsend msg: yes sir!Static Proxy after: sendProcess finished with exit code 0 JDK 代理原始类和原始接口同静态代理 JDK 动态代理类12345678910111213141516171819202122232425package vip.housir.proxy;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;/** * @author housirvip */public class LogInvocationHandler implements InvocationHandler { private final Object obj; public LogInvocationHandler(Object obj) { this.obj = obj; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(&quot;Dynamic Proxy before: &quot; + method.getName()); // 反射调用方法， 动态增强 Object result = method.invoke(obj, args); System.out.println(&quot;Dynamic Proxy after: &quot; + method.getName()); return result; }} 代理工厂1234567891011121314151617package vip.housir.proxy;import java.lang.reflect.Proxy;/** * @author housirvip */public class JdkProxyFactory { public static Object createLogProxy(Object obj) { return Proxy.newProxyInstance( obj.getClass().getClassLoader(), obj.getClass().getInterfaces(), new LogInvocationHandler(obj) ); }} 手动调用12345678910111213import org.junit.Test;import vip.housir.proxy.JdkProxyFactory;import vip.housir.proxy.SmsService;import vip.housir.proxy.SmsServiceImpl;public class TestJdkDynamicProxy { @Test public void testJdkDynamicProxy() { SmsService sms = (SmsService) JdkProxyFactory.createLogProxy(new SmsServiceImpl()); sms.send(&quot;yes sir!&quot;); }} 结果输出12345Dynamic Proxy before: sendsend msg: yes sir!Dynamic Proxy after: sendProcess finished with exit code 0 Cglib 代理POM 引入依赖123456&lt;!-- https://mvnrepository.com/artifact/cglib/cglib --&gt; &lt;dependency&gt; &lt;groupId&gt;cglib&lt;/groupId&gt; &lt;artifactId&gt;cglib&lt;/artifactId&gt; &lt;version&gt;3.2.5&lt;/version&gt; &lt;/dependency&gt; 原始类1234567891011package vip.housir.proxy;/** * @author housirvip */public class SmsSender { public void send(String msg){ System.out.println(&quot;send msg: &quot; + msg); }} Cglib 代理增强类123456789101112131415161718192021package vip.housir.proxy;import net.sf.cglib.proxy.MethodInterceptor;import net.sf.cglib.proxy.MethodProxy;import java.lang.reflect.Method;/** * @author housirvip */public class LogMethodInterceptor implements MethodInterceptor { @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable { System.out.println(&quot;Dynamic Proxy before: &quot; + method.getName()); // 代理调用父类方法， 动态增强 Object result = methodProxy.invokeSuper(o, objects); System.out.println(&quot;Dynamic Proxy after: &quot; + method.getName()); return result; }} 代理工厂123456789101112131415161718package vip.housir.proxy;import net.sf.cglib.proxy.Enhancer;/** * @author housirvip */public class CglibProxyFactory { public static Object createLogProxy(Class&lt;?&gt; c) { Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(c); enhancer.setClassLoader(c.getClassLoader()); //设置增强类的实现逻辑 enhancer.setCallback(new LogMethodInterceptor()); return enhancer.create(); }} 手动调用123456789101112import org.junit.Test;import vip.housir.proxy.SmsSender;import vip.housir.proxy.CglibProxyFactory;public class TestDynamicProxy { @Test public void testCglibDynamicProxy() { SmsSender sms = (SmsSender) CglibProxyFactory.createLogProxy(SmsSender.class); sms.send(&quot;yes sir!&quot;); }} 结果输出12345Dynamic Proxy before: sendsend msg: yes sir!Dynamic Proxy after: sendProcess finished with exit code 0 对比静态代理和动态代理 动态代理更加灵活，不需要必须实现接口，可以直接代理实现类，并且可以不需要针对每个目标类都创建一个代理类。 静态代理中，接口一旦新增加方法，目标对象和代理对象都要进行修改，非常麻烦。 静态代理在编译时就将接口、实现类、代理类这些都变成了一个个实际的 class 文件，而动态代理是在运行时动态生成类字节码，并加载到 JVM 中。 JDK 代理和 CGLIB 代理 JDK 动态代理只能只能代理实现了接口的类，而 CGLIB 可以代理未实现任何接口的类。 CGLIB 动态代理是通过生成一个被代理类的子类来拦截被代理类的方法调用，因此不能代理声明为 final 类型的类和方法。 就二者的效率来说，大部分情况都是 JDK 动态代理更优秀，随着 JDK 版本的升级，这个优势更加明显。","link":"/2020/09/02/dynamic-proxy/"},{"title":"Gogs + Drone 在 Docker 下配置持续集成","text":"安装 Gogs 建议使用 docker 12sudo docker run -d --name=gogs -p 3022:22 -p 3000:3000 -v /gogs/data:/data gogs/gogs# 输入密码 设置数据库连接方式，连接Mysql，待配置完成后，可登陆使用，可以作为私有 git 仓库，UI 比较简洁，基于 go 开发，性能很不错，而且占用系统资源非常少。 安装 Drone 建议使用 docker 1234567891011121314151617181920212223242526272829303132# 在 docker 下先创建一个网络 drone，之后 drone server 和 runner 都加入这个网络sudo docker network create drone# 先安装 drone serversudo docker run -d \\ -e DRONE_AGENTS_ENABLED=true \\ -e DRONE_GOGS_SERVER=http://192.168.100.3:3000 \\ -e DRONE_RPC_SECRET=RdZneT4mOT2v1MCOdA3tLW2CtyHxnWaU \\ -e DRONE_SERVER_HOST=192.168.100.226:8080 \\ -e DRONE_SERVER_PROTO=http \\ -e DRONE_DATABASE_DRIVER=mysql \\ -e DRONE_DATABASE_DATASOURCE='root:housirvip@tcp(192.168.100.3:3306)/drone?parseTime=true' \\ -e TZ=Asia/Shanghai \\ -p 8080:80 \\ -p 8443:443 \\ --name=drone \\ --network drone \\ drone/drone:1 # 在安装 drone runnersudo docker run -d \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -e DRONE_RPC_PROTO=http \\ -e DRONE_RPC_HOST=drone \\ -e DRONE_RPC_SECRET=RdZneT4mOT2v1MCOdA3tLW2CtyHxnWaU \\ -e DRONE_RUNNER_CAPACITY=2 \\ -e DRONE_RUNNER_NAME=${HOSTNAME} \\ -e TZ=Asia/Shanghai \\ -p 3000:3000 \\ --name runner \\ --network drone \\ drone/drone-runner-docker:1 Drone 设置 CLI12345678910111213# mac 上brew tap drone/dronebrew install drone# linux 上curl -L https://github.com/drone/drone-cli/releases/latest/download/drone_linux_amd64.tar.gz | tar zxsudo install -t /usr/local/bin drone# 配置 cli 登陆，建议写入 .bashrc .zshrc 等文件中export DRONE_SERVER=http://192.168.100.226:8080export DRONE_TOKEN=RZtKdJC32PNT1EeE93xBkcqTasdGwqbvdrone info Drone 设置 CronJob123456drone cron add [repo] [name] [time]# 每天执行一次drone cron add &quot;org/repo&quot; &quot;name&quot; &quot;0 0 0 * * *&quot;# 每小时执行一次drone cron add &quot;org/repo&quot; &quot;name&quot; &quot;0 0 * * * *&quot; 也可以在 UI 中设置，但是没法设置时间，只能选择预设 Drone 设置 Secret12345678drone secret add [repo] [name] [value]# 例如在 housirvip/hello-world 项目下设置 my_token=e72e16c7e42f29drone secret add housirvip/hello-world my_token e72e16c7e42f29# 针对 organization 设置，在这个组织下的所有项目都会生效drone orgsecret add [organization] [name] [data]# 例如在 housirvip 下设置 my_token=e72e16c7e42f29drone orgsecret add housirvip my_token e72e16c7e42f29 也可以在 UI中设置，但是不能设置 orgsecret Drone 设置 Pipeline123456789101112131415161718---kind: pipelinename: node14steps:- name: npm_run_start image: node:14 commands: - npm install - npm run start environment: JD_COOKIE: from_secret: JD_COOKIE JD_COOKIE_2: from_secret: JD_COOKIE_2 SERVER_CHAN: from_secret: SERVER_CHAN UPDATE: true 配置完成配置完成后不仅可以自动对新提交的代码进行编译测试，也可以定时执行脚本，如签到、打卡之类的脚本，下图就是京东 APP 自动签到，领京豆的一个小脚本，蚊子腿，积少成多~","link":"/2021/03/25/gogs-drone/"},{"title":"哈希表 Hashmap","text":"本文中贴出的代码为jdk 1.8 重要参数12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * The default initial capacity - MUST be a power of two. * 默认初始化容量，2的4次方 */static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16/** * The maximum capacity, used if a higher value is implicitly specified * by either of the constructors with arguments. * MUST be a power of two &lt;= 1&lt;&lt;30. * 最大容量，必须是2的整数幂，方便取模 */static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;/** * The load factor used when none specified in constructor. * 默认加载因子，当使用量达到这个比例以后会扩容 */static final float DEFAULT_LOAD_FACTOR = 0.75f;/** * The bin count threshold for using a tree rather than list for a * bin. Bins are converted to trees when adding an element to a * bin with at least this many nodes. The value must be greater * than 2 and should be at least 8 to mesh with assumptions in * tree removal about conversion back to plain bins upon * shrinkage. * 当拉链增加到8以后，转化为红黑树，这里jdk1.8，区别于1.7 */static final int TREEIFY_THRESHOLD = 8;/** * The bin count threshold for untreeifying a (split) bin during a * resize operation. Should be less than TREEIFY_THRESHOLD, and at * most 6 to mesh with shrinkage detection under removal. * 当红黑树低到6以后，转化为拉链，这里jdk1.8，区别于1.7 */static final int UNTREEIFY_THRESHOLD = 6;/** * The smallest table capacity for which bins may be treeified. * (Otherwise the table is resized if too many nodes in a bin.) * Should be at least 4 * TREEIFY_THRESHOLD to avoid conflicts * between resizing and treeification thresholds. */static final int MIN_TREEIFY_CAPACITY = 64; HashMap在new的时候，有3种方式，可以指定初始容量和加载因子，也可以不指定，默认即可。 如果在创建HashMap实例时没有给定capacity、loadFactor则默认值分别是16和0.75。 当好多bin被映射到同一个桶时，如果这个桶中bin的数量小于TREEIFY_THRESHOLD当然不会转化成树形结构存储。 如果这个桶中bin的数量大于了 TREEIFY_THRESHOLD ，但是capacity小于MIN_TREEIFY_CAPACITY 则依然使用链表结构进行存储，此时会对HashMap进行扩容。 如果capacity大于了MIN_TREEIFY_CAPACITY ，则会进行树化。 12345678910111213141516171819202122232425262728293031323334353637383940/** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the specified initial * capacity and load factor. * * @param initialCapacity the initial capacity * @param loadFactor the load factor * @throws IllegalArgumentException if the initial capacity is negative * or the load factor is nonpositive */ public HashMap(int initialCapacity, float loadFactor) { if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); } /** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the specified initial * capacity and the default load factor (0.75). * * @param initialCapacity the initial capacity. * @throws IllegalArgumentException if the initial capacity is negative. */ public HashMap(int initialCapacity) { this(initialCapacity, DEFAULT_LOAD_FACTOR); } /** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the default initial capacity * (16) and the default load factor (0.75). */ public HashMap() { this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted } get123456789101112131415161718192021222324public V get(Object key) { Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;}final Node&lt;K,V&gt; getNode(int hash, Object key) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) { if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) { if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; } while ((e = e.next) != null); } } return null;} 对 key 取 hash ，定位桶的位置。 如果桶为空，返回 null 。 判断桶的 first 的 key 是否为查询的 key，是就返回 value。 桶的 first 不匹配，则判断 first 是红黑树 or 链表。 红黑树就则 getTreeNode。 或者链表则遍历判断 next。 如何计算 hash解决哈希碰撞时，取模是一个常用方式，比如 n%k 当且仅当k为2的整数幂时，n%k==n&amp;(k-1) 通过位运算来进行快速取模，因此必须要求容量为2的整数幂 put12345678910111213141516171819202122232425262728293031323334353637383940414243444546public V put(K key, V value) { return putVal(hash(key), key, value, false, true);}final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else { Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else { for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; } } if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;} put 操作复杂一些，要判断容量，是否扩容，还要判断桶中bin数量，来决定是否转换为红黑树或者链表 判断当前桶是否为空，空就需要初始化（resize 中会判断是否进行初始化）。 根据当前 key 的 hashcode 定位到具体的桶中并判断是否为空，为空表明没有 Hash 冲突就直接在当前位置创建一个新桶。 如果当前桶不为空（Hash 冲突），需要比较当前桶中的 key、key 的 hashcode 与写入的 key 是否相等，相等就赋值给 e，在第 8 步的时候会统一进行赋值及返回。 如果当前桶为红黑树，按照红黑树的方式写入数据。 如果是链表，就需要将当前的 key、value 封装成一个新节点写入到当前桶的后面（形成链表）。接着判断当前链表的大小是否大于预设的阈值，大于时就要转换为红黑树。 如果在遍历过程中找到 key 相同时直接退出遍历。 如果 e != null 就相当于存在相同的 key,那就需要将值覆盖。最后判断是否需要进行扩容。 resize12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273final Node&lt;K,V&gt;[] resize() { Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) { if (oldCap &gt;= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold } else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else { // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } if (newThr == 0) { float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; @SuppressWarnings({&quot;rawtypes&quot;,&quot;unchecked&quot;}) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) { for (int j = 0; j &lt; oldCap; ++j) { Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) { oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else { // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do { next = e.next; if ((e.hash &amp; oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); if (loTail != null) { loTail.next = null; newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab;} 如何进行 rehashget方法可以使用位运算快速取模，同样的，我们在扩充HashMap的时候，不需要重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap” 因此，resize每次扩容1倍","link":"/2020/09/09/hashmap/"},{"title":"手写RPC 之 Hrpc Version 1.0","text":"Github地址 Github: https://github.com/housirvip/hrpc 原理 客户端，通过接口调用，如 UserService，UserService.login(username, password)，实际上是通过动态代理，代理执行 login 方法，在执行逻辑中，通过网络调用服务端的 UserService 实际实现类。 服务端，通过网络获取到请求的 className，method，以及各种参数 args，来反射调用 UserService 的实现类，并将执行结果，通过网络返回至客户端中。 公共代码放在 core 包中，HrpcRequest，HrpcResponse，HrpcService 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package vip.housir.hrpc.core;import java.io.Serializable;/** * @author housirvip */public class HrpcResponse implements Serializable { private int statusCode; private Object body; private String message; public int getStatusCode() { return statusCode; } public void setStatusCode(int statusCode) { this.statusCode = statusCode; } public Object getBody() { return body; } public void setBody(Object body) { this.body = body; } public String getMessage() { return message; } public void setMessage(String message) { this.message = message; } @Override public String toString() { return &quot;HrpcResponse{&quot; + &quot;statusCode=&quot; + statusCode + &quot;, body=&quot; + body + &quot;, message='&quot; + message + '\\'' + '}'; }} 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package vip.housir.hrpc.core;import java.io.Serializable;import java.util.Arrays;/** * @author housirvip */public class HrpcRequest implements Serializable { private String className; private String methodName; private Object[] args; private Class&lt;?&gt;[] types; public String getClassName() { return className; } public void setClassName(String className) { this.className = className; } public String getMethodName() { return methodName; } public void setMethodName(String methodName) { this.methodName = methodName; } public Object[] getArgs() { return args; } public void setArgs(Object[] args) { this.args = args; } public Class&lt;?&gt;[] getTypes() { return types; } public void setTypes(Class&lt;?&gt;[] types) { this.types = types; } @Override public String toString() { return &quot;HrpcRequest{&quot; + &quot;className='&quot; + className + '\\'' + &quot;, methodName='&quot; + methodName + '\\'' + &quot;, args=&quot; + Arrays.toString(args) + &quot;, types=&quot; + Arrays.toString(types) + '}'; }} 自定义 service 均继承于 HrpcService 123456789package vip.housir.hrpc.core;import java.io.Serializable;/** * @author housirvip */public interface HrpcService extends Serializable {} Client 包 动态代理的具体实现方法，实际通过网络远程调用 12345678910111213141516171819202122232425262728293031323334353637383940package vip.housir.hrpc.client.proxy;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import vip.housir.hrpc.core.HrpcRequest;import vip.housir.hrpc.core.HrpcResponse;import vip.housir.hrpc.client.transport.Transport;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;/** * @author housirvip */public class RequestInvocationHandler implements InvocationHandler { private static final Logger logger = LoggerFactory.getLogger(RequestInvocationHandler.class); private final Transport transport; public RequestInvocationHandler(Transport transport) { this.transport = transport; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { HrpcRequest request = new HrpcRequest(); request.setMethodName(method.getName()); request.setClassName(method.getDeclaringClass().getName()); request.setArgs(args); request.setTypes(method.getParameterTypes()); logger.debug(request.toString()); HrpcResponse response = transport.send(request); logger.debug(response.toString()); return response.getBody(); }} 代理工厂，创建代理 1234567891011121314151617package vip.housir.hrpc.client.proxy;import vip.housir.hrpc.client.transport.SocketTransport;import java.lang.reflect.Proxy;/** * @author housirvip */public class RequestProxyFactory { @SuppressWarnings(&quot;unchecked&quot;) public static &lt;T&gt; T createProxy(final Class&lt;T&gt; clazz, SocketTransport transport) { return (T) Proxy.newProxyInstance(clazz.getClassLoader(), new Class&lt;?&gt;[]{clazz}, new RequestInvocationHandler(transport)); }} 网络请求的接口 123456789101112131415161718package vip.housir.hrpc.client.transport;import vip.housir.hrpc.core.HrpcRequest;import vip.housir.hrpc.core.HrpcResponse;/** * @author housirvip */public interface Transport { /** * 远程调用，发送请求 * * @param request HrpcRequest * @return HrpcResponse */ HrpcResponse send(HrpcRequest request);} 网络请求接口的实现方式，通过 socket 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package vip.housir.hrpc.client.transport;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import vip.housir.hrpc.core.HrpcRequest;import vip.housir.hrpc.core.HrpcResponse;import java.io.*;import java.net.Socket;/** * @author housirvip */public class SocketTransport implements Transport { private static final Logger logger = LoggerFactory.getLogger(SocketTransport.class); private final String host; private final int port; public SocketTransport(String host, int port) { this.host = host; this.port = port; } @Override public HrpcResponse send(HrpcRequest request) { Socket socket = null; ObjectOutputStream outputStream = null; ObjectInputStream inputStream = null; HrpcResponse response = null; try { socket = new Socket(host, port); outputStream = new ObjectOutputStream(socket.getOutputStream()); outputStream.writeObject(request); outputStream.flush(); inputStream = new ObjectInputStream(socket.getInputStream()); response = (HrpcResponse) inputStream.readObject(); } catch (Exception e) { logger.error(e.getMessage(), e); } finally { try { if (inputStream != null) { inputStream.close(); } if (outputStream != null) { outputStream.close(); } if (socket != null) { socket.close(); } } catch (IOException e) { logger.error(e.getMessage(), e); } } return response; }} Server 包 服务发布接口 123456789101112131415161718192021222324package vip.housir.hrpc.server.publisher;import vip.housir.hrpc.core.HrpcService;import java.util.Map;/** * @author housirvip */public interface Publisher { /** * 发布服务 * * @param port 端口号 * @param services 发布的服务 */ void publish(int port, Map&lt;String, HrpcService&gt; services); /** * 停止服务发布 */ void shutdown();} 服务发布接口的实现，通过线程池来处理多客户端的请求 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package vip.housir.hrpc.server.publisher;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import vip.housir.hrpc.core.HrpcService;import vip.housir.hrpc.server.processor.ProcessorThread;import java.io.IOException;import java.net.ServerSocket;import java.net.Socket;import java.util.Map;import java.util.concurrent.*;/** * @author housirvip */public class SocketPublisher implements Publisher { private static final Logger logger = LoggerFactory.getLogger(SocketPublisher.class); private final ExecutorService executor; public SocketPublisher() { executor = new ThreadPoolExecutor(5, 10, 60L, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;()); } @Override public void publish(int port, Map&lt;String, HrpcService&gt; services) { ServerSocket serverSocket = null; try { serverSocket = new ServerSocket(port); while (true) { Socket socket = serverSocket.accept(); executor.execute(new ProcessorThread(socket, services)); } } catch (IOException e) { logger.error(e.getMessage(), e); } finally { try { if (serverSocket != null) { serverSocket.close(); } } catch (IOException e) { e.printStackTrace(); } } } @Override public void shutdown() { executor.shutdown(); }} socket 通讯，接到请求后的具体实现 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273package vip.housir.hrpc.server.processor;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import vip.housir.hrpc.core.HrpcRequest;import vip.housir.hrpc.core.HrpcResponse;import vip.housir.hrpc.core.HrpcService;import java.io.IOException;import java.io.ObjectInputStream;import java.io.ObjectOutputStream;import java.lang.reflect.Method;import java.net.Socket;import java.util.Map;/** * @author housirvip */public class ProcessorThread implements Runnable { private static final Logger logger = LoggerFactory.getLogger(ProcessorThread.class); private final Socket socket; private final Map&lt;String, HrpcService&gt; services; public ProcessorThread(Socket socket, Map&lt;String, HrpcService&gt; services) { this.socket = socket; this.services = services; } @Override public void run() { ObjectInputStream inputStream = null; ObjectOutputStream outputStream = null; try { inputStream = new ObjectInputStream(socket.getInputStream()); outputStream = new ObjectOutputStream(socket.getOutputStream()); HrpcRequest request = (HrpcRequest) inputStream.readObject(); logger.debug(request.toString()); Class&lt;?&gt; clazz = Class.forName(request.getClassName()); Method method = clazz.getMethod(request.getMethodName(), request.getTypes()); HrpcService service = services.get(request.getClassName()); Object body = method.invoke(service, request.getArgs()); HrpcResponse response = new HrpcResponse(); response.setBody(body); response.setStatusCode(200); logger.debug(response.toString()); outputStream.writeObject(response); outputStream.flush(); } catch (Exception e) { logger.error(e.getMessage(), e); } finally { try { if (inputStream != null) { inputStream.close(); } if (outputStream != null) { outputStream.close(); } socket.close(); } catch (IOException e) { logger.error(e.getMessage(), e); } } }} Demo 调用示例 业务 service 的接口，UserService 123456789101112131415161718package vip.housir.hrpc.demo.service;import vip.housir.hrpc.core.HrpcService;/** * @author housirvip */public interface UserService extends HrpcService { /** * 实现用户登录功能 * * @param username 用户名 * @param password 密码 * @return 用户令牌 */ String login(String username, String password);} 业务 service 的实现 1234567891011121314package vip.housir.hrpc.demo.service.impl;import vip.housir.hrpc.demo.service.UserService;/** * @author housirvip */public class UserServiceImpl implements UserService { @Override public String login(String username, String password) { return &quot;这是server端返回的结果：&quot; + username + &quot;@&quot; + password; }} HrpcClient 12345678910111213141516171819202122232425package vip.housir.hrpc.demo;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import vip.housir.hrpc.demo.service.UserService;import vip.housir.hrpc.client.proxy.RequestProxyFactory;import vip.housir.hrpc.client.transport.SocketTransport;/** * @author housirvip */public class HrpcClient { private static final Logger logger = LoggerFactory.getLogger(HrpcClient.class); public static void main(String[] args) { SocketTransport transport = new SocketTransport(&quot;localhost&quot;, 7788); UserService userService = RequestProxyFactory.createProxy(UserService.class, transport); for (int i = 0; i &lt; 1000; i++) { String token = userService.login(&quot;housir&quot;, &quot;vip&quot;); logger.info(token); } }} HrpcServer 123456789101112131415161718192021222324package vip.housir.hrpc.demo;import vip.housir.hrpc.demo.service.UserService;import vip.housir.hrpc.core.HrpcService;import vip.housir.hrpc.server.publisher.SocketPublisher;import vip.housir.hrpc.demo.service.impl.UserServiceImpl;import java.util.HashMap;import java.util.Map;/** * @author housirvip */public class HrpcServer { public static void main(String[] args) { Map&lt;String, HrpcService&gt; services = new HashMap&lt;&gt;(8); services.put(UserService.class.getName(), new UserServiceImpl()); SocketPublisher processor = new SocketPublisher(); processor.publish(7788, services); }} 输出结果Server Client TODO 在之后的 Hrpc version 2.3.4……..n 中预计实现，可能版本号起的很随意哈哈 引入 Netty 进行 io 多路复用 支持服务的注册和发现 服务优雅的关闭 支持 bean 的容器化管理，实现通过注解注入依赖 支持多种类型序列化编码方式 json，xml，protobuf","link":"/2020/09/15/hrpc-version-1/"},{"title":"Java 复习 面经总结","text":"Java相关8 种基本类型 String String是不可变对象, 意思是一旦创建,那么整个对象就不可改变. 即使新手觉得String引用变了,实际上只是(指针)引用指向了另一个(新的)对象，而程序员可以明确地对字符数组进行修改,因此敏感信息(如密码)不容易在其他地方暴露(只要你用完后对char[]置0)。 Java 的 8 种基本数据类型中不包括 String，基本数据类型中用来描述文本数据的是 char == 与 equals 简单来说, ==判断两个引用的是不是同一个内存地址(同一个物理对象)。而 equals() 是可以重写的一个方法，默认直接 return a==b; String 的 equals 先判断内存地址，再比较值相等。 hashCode 与 equals hashCode()与equals()的相关规定 如果两个对象相等，则hashcode一定也是相同的 两个对象相等，对两个对象分别调用equals方法都返回true 两个对象有相同的hashcode值，它们也不一定是相等的 因此，equals 方法被覆盖过，则 hashCode 方法也必须被覆盖 hashCode() 的默认行为是对堆上的对象产生独特值。如果没有重写 hashCode()，则该 class 的两个对象无论如何都不会相等（即使这两个对象指向相同的数据） 访问修饰符 private : 在同一类内可见。使用对象：变量、方法。 注意：不能修饰类（外部类） default (即缺省，什么也不写，不使用任何关键字）: 在同一包内可见，不使用任何修饰符。使用对象：类、接口、变量、方法。 protected : 对同一包内的类和所有子类可见。使用对象：变量、方法。 注意：不能修饰类（外部类）。 public : 对所有类可见。使用对象：类、接口、变量、方法 重载、重写 构造器不能被继承，因此不能被重写，但可以被重载。 方法的重载和重写都是实现多态的方式，区别在于前者实现的是编译时的多态性，而后者实现的是运行时的多态性。重载：发生在同一个类中，方法名相同参数列表不同（参数类型不同、个数不同、顺序不同），与方法返回值和访问修饰符无关，即重载的方法不能根据返回类型进行区分 重写：发生在父子类中，方法名、参数列表必须相同，返回值小于等于父类，抛出的异常小于等于父类，访问修饰符大于等于父类（里氏代换原则）；如果父类方法访问修饰符为private则子类中就不是重写。 栈溢出 栈是线程私有的，栈的生命周期和线程一样，每个方法在执行的时候就会创建一个栈帧，它包含局部变量表、操作数栈、动态链接、方法出口等信息，局部变量表又包括基本数据类型和对象的引用； 当线程请求的栈深度超过了虚拟机允许的最大深度时，会抛出StackOverFlowError异常，方法递归调用肯可能会出现该问题； 调整参数-xss去调整jvm栈的大小 OOM原因 无法在 Java 堆中分配对象 应用程序保存了无法被GC回收的对象 应用程序过度使用 finalizer 常见类型Java Heap 溢出 堆 存放实例对象和数组，线程共享。 一般的异常信息：java.lang.OutOfMemoryError:Java heap spacess java堆用于存储对象实例，我们只要不断的创建对象，并且保证GC Roots到对象之间有可达路径来避免垃圾回收机制清除这些对象，就会在对象数量达到最大堆容量限制后产生内存溢出异常。 出现这种异常，一般手段是先通过内存映像分析工具(如Eclipse Memory Analyzer)对dump出来的堆转存快照进行分析，重点是确认内存中的对象是否是必要的，先分清是因为内存泄漏(Memory Leak)还是内存溢出(Memory Overflow)。 如果是内存泄漏，可进一步通过工具查看泄漏对象到GC Roots的引用链。于是就能找到泄漏对象时通过怎样的路径与GC Roots相关联并导致垃圾收集器无法自动回收。 如果不存在泄漏，那就应该检查虚拟机的参数(-Xmx与-Xms)的设置是否适当。 虚拟机栈和本地方法栈溢出 虚拟机栈是jvm执行java代码所使用的栈。 本地方法栈是jvm调用操作系统方法所使用的栈。 本地方法栈类似虚拟机栈，但是只为Native方法服务。 如果线程请求的栈深度大于虚拟机所允许的最大深度，将抛出StackOverflowError异常。 如果虚拟机在扩展栈时无法申请到足够的内存空间(不断创建线程)，则抛出OutOfMemoryError异常 这里需要注意当栈的大小越大可分配的线程数就越少。 运行时常量池溢出 方法区一部分。存放编译期生成的各种字面量和符号引用。 异常信息：java.lang.OutOfMemoryError:PermGen space 如果要向运行时常量池中添加内容，最简单的做法就是使用String.intern()这个Native方法。该方法的作用是：如果池中已经包含一个等于此String的字符串，则返回代表池中这个字符串的String对象；否则，将此String对象包含的字符串添加到常量池中，并且返回此String对象的引用。由于常量池分配在方法区内，我们可以通过-XX:PermSize和-XX:MaxPermSize限制方法区的大小，从而间接限制其中常量池的容量。 方法区溢出 用于存储已被JVM加载的类信息，类名、访问修饰符、常量池、字段描述、方法描述等。，即时编译器编译后的代码，线程共享。 异常信息：java.lang.OutOfMemoryError:PermGen space 方法区溢出也是一种常见的内存溢出异常，一个类如果要被垃圾收集器回收，判定条件是很苛刻的。在经常动态生成大量Class的应用中，要特别注意这点。 排查方法 查找关键报错信息，如java.lang.OutOfMemoryError: Java heap space 使用内存映像分析工具（如Eclipsc Memory Analyzer或者Jprofiler）对Dump出来的堆储存快照进行分析，分析清楚是内存泄漏还是内存溢出。 如果是内存泄漏，可进一步通过工具查看泄漏对象到GC Roots的引用链，修复应用程序中的内存泄漏。 如果不存在泄漏，先检查代码是否有死循环，递归等，再考虑用 -Xmx 增加堆大小。 区别于面向过程 就像蛋炒饭（面向对象）和盖浇饭（面向过程）的区别 JVM 内存空间 线程独享：JVM栈，程序计数器，本地方法栈 线程共享：堆，方法区 程序计数器：线程私有的，是一块很小的内存空间，作为当前线程的行号指示器，用于记录当前虚拟机正在执行的线程指令地址； 虚拟机栈：线程私有的，每个方法执行的时候都会创建一个栈帧，用于存储局部变量表、操作数、动态链接和方法返回等信息，当线程请求的栈深度超过了虚拟机允许的最大深度时，就会抛出StackOverFlowError； 本地方法栈：线程私有的，保存的是native方法的信息，当一个jvm创建的线程调用native方法后，jvm不会在虚拟机栈中为该线程创建栈帧，而是简单的动态链接并直接调用该方法； 堆：java堆是所有线程共享的一块内存，几乎所有对象的实例和数组都要在堆上分配内存，因此该区域经常发生垃圾回收的操作； 方法区：存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码数据。即永久代，在jdk1.8中不存在方法区了，被元数据区替代了，原方法区被分成两部分；1：加载的类信息，2：运行时常量池；加载的类信息被保存在元数据区中，运行时常量池保存在堆中； JVM 堆内存空间 新生代（eden，survivor），老年代，永久代（元空间） 新生带（年轻代）：新对象和没达到一定年龄的对象都在年轻代 老年代：被长时间使用的对象，老年代的内存空间应该要比年轻代更大 元空间（JDK1.8之前叫永久代）：像一些方法中的操作临时对象等，JDK1.8之前是占用JVM内存，JDK1.8之后直接使用物理内存 堆内存调参 -Xms：设置初始分配大小，默认为物理内存的1/64 -Xmx：最大分配内存，默认为物理内存的1/4 -XX:+PrintGCDetails：输出详细的GC处理日志 -XX:+PrintGCTimeStamps：输出GC的时间戳信息 -XX:+PrintGCDateStamps：输出GC的时间戳信息（以日期的形式） -XX:+PrintHeapAtGC：在GC进行处理的前后打印堆内存信息 -Xloggc:(SavePath)：设置日志信息保存文件 在堆内存的调整策略中，基本上只要调整两个参数：-Xms和-Xmx JVM 垃圾回收垃圾回收算法 标记-清除算法 标记-整理算法 复制算法（新生代） 标记-清除 第一步：利用可达性去遍历内存，把存活对象和垃圾对象进行标记； 第二步：在遍历一遍，将所有标记的对象回收掉； 特点：效率不行，标记和清除的效率都不高；标记和清除后会产生大量的不连续的空间分片，可能会导致之后程序运行的时候需分配大对象而找不到连续分片而不得不触发一次GC； 标记-整理 第一步：利用可达性去遍历内存，把存活对象和垃圾对象进行标记； 第二步：将所有的存活的对象向一段移动，将端边界以外的对象都回收掉； 特点：适用于存活对象多，垃圾少的情况；需要整理的过程，无空间碎片产生； 复制算法 将内存按照容量大小分为大小相等的两块，每次只使用一块，当一块使用完了，就将还存活的对象移到另一块上，然后在把使用过的内存空间移除； 特点：不会产生空间碎片；内存使用率极低； 分代收集 根据内存对象的存活周期不同，将内存划分成几块，java虚拟机一般将内存分成新生代和老生代，在新生代中，有大量对象死去和少量对象存活，所以采用复制算法，只需要付出少量存活对象的复制成本就可以完成收集； 老年代中因为对象的存活率极高，没有额外的空间对他进行分配担保，所以采用标记清理或者标记整理算法进行回收； GC 相关java堆 = 新生代+老年代； 新生代 = Eden + Suivivor（S0 + S1），默认分配比例是 8:1:1 当Eden区空间满了的时候，就会触发一次Minor GC，以收集新生代的垃圾，存活下来的对象会被分配到Survivor区 大对象（需要大量连续内存空间的对象）会直接被分配到老年代 如果对象在Eden中出生，并且在经历过一次Minor GC之后仍然存活，被分配到存活区的话，年龄+1，此后每经历过一次 Minor GC并且存活下来，年龄就+1，当年龄达到15的时候，会被晋升到老年代 当老年代满了，而无法容纳更多对象的话，会触发一次full gc；full gc存储的是整个内存堆（包括年轻代和老年代） Major GC是发生在老年代的GC，清理老年区，经常会伴随至少一次minor gc cms 和 g1cms CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。 CMS收集器仅作用于老年代的收集，是基于标记-清除算法，2次 stop the world 初始标记（CMS initial mark）(stop the world) 并发标记（CMS concurrent mark） 重新标记（CMS remark）(stop the world) 并发清除（CMS concurrent sweep） 其中，初始标记、重新标记这两个步骤仍然需要Stop-the-world。初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，并发标记阶段就是进行GC Roots Tracing的过程，而重新标记阶段则是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始阶段稍长一些，但远比并发标记的时间短。 g1 G1重新定义了堆空间，打破了原有的分代模型，将堆划分为一个个区域。这么做的目的是在进行收集时不必在全堆范围内进行，这是它最显著的特点。区域划分的好处就是带来了停顿时间可预测的收集模型 初始标记（Initial Marking）：仅仅只是标记一下GC Roots能直接关联到的对象，并且修改TAMS（Next Top at Mark Start）的值，让下一阶段用户程序并发运行时，能在正确可用的Region中创建新对象，这阶段需要停顿线程，但耗时很短。 并发标记（Concurrent Marking）：是从GC Roots开始堆中对象进行可达性分析，找出存活的对象，这阶段耗时较长，但可与用户程序并发执行。 最终标记（Final Marking）：是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程Remembered Set Logs里面，最终标记阶段需要把Remembered Set Logs的数据合并到Remembered Set中，这阶段需要停顿线程，但是可并行执行。 筛选回收（Live Data Counting and Evacuation）：首先对各个Region的回收价值和成本进行排序，根据用户所期望的GC停顿时间来制定回收计划。这个阶段也可以做到与用户程序一起并发执行，但是因为只回收一部分Region，时间是用户可控制的，而且停顿用户线程将大幅提高收集效率。 JMM 内存模型volatile 关键字指令重排 为了遵守as-if-serial语义, 编译器和处理器不会对存在数据依赖关系的操作做重排序, 因为这种重排序会改变执行结果. 但是,如果操作之间不存在数据依赖关系, 这些操作就可能被编译器和处理器重排序. 编译器优化的重排序: 编译器在不改变单线程程序语义的前提下, 可以重新安排语句的执行顺序. 指令级并行的重排序: 现代处理器采用了指令级并行技术(Instruction-Level Parallelism, ILP)来将多条指令重叠执行. 如果不存在数据依赖性, 处理器可以改变语句对应机器指令的执行顺序. 内存系统的重排序: 由于处理器使用缓存和读/写缓冲区, 这使得加载和存储操作看上去可能是在乱序执行. 内存屏障 volatile写对于volatile变量的写，按照JMM的标准，需要插入两条内存屏障： 123StoreStore；volatile_write_code;StoreLoad; 解释下，在写volatile之前插入了storestore指令，意味着volatile之前的普通写操作需要先于volatile操作执行，也就是不允许之前的普通写操作，与volatile写操作重排序。符合JMM对volatile关键字的规则。 在写volatile之后，需要加入StoreLoad指令，也就是先把volatile变量的最新值刷新到主内存（store），然后再执行后续的操作。同样不允许volatile写操作与后续的读、写操作重排序。 volatile读对于volatile的读，按照JMM的标准，同样需要查询两条内存屏障，但是不同于上述的写操作，这块都是插入在volatile_code之后的。 123volatile_read_code;LoadLoad;LoadStore; 这里的LoadLoad用于禁止下面的普通读操作与volatile读重排序，LoadStore则禁止普通写操作与volatile读操作重排序。 Java 跨平台机制 Java源代码经过虚拟机编译器编译后产生的文件（即扩展为.class的文件），它不面向任何特定的处理器，只面向虚拟机。 好处Java语言通过字节码的方式，在一定程度上解决了传统解释型语言执行效率低的问题，同时又保留了解释型语言可移植的特点。所以Java程序运行时比较高效，而且，由于字节码并不专对一种特定的机器，因此，Java程序无须重新编译便可在多种不同的计算机上运行。 编译型 or 解释型暂无定论 Java源代码----&gt;编译器----&gt;jvm可执行的Java字节码(即虚拟指令)----&gt;jvm----&gt;jvm中解释器-----&gt;机器可执行的二进制机器码----&gt;程序运行 类的加载机制 虚拟机把描述类的数据加载到内存里面，并对数据进行校验、解析和初始化，最终变成可以被虚拟机直接使用的class对象； 装载：查找和导入Class文件 链接：把类的二进制数据合并到JRE中 校验：检查载入Class文件数据的正确性 准备：给类的静态变量分配存储空间（赋0值） 解析：将符号引用转成直接引用； 初始化：对类的静态变量，静态代码块执行初始化操作（赋初始值） 类加载器 类加载器是指：通过一个类的全限定性类名获取该类的二进制字节流叫做类加载器 启动类加载器：用来加载java核心类库，无法被java程序直接引用； 扩展类加载器：用来加载java的扩展库，java的虚拟机实现会提供一个扩展库目录，该类加载器在扩展库目录里面查找并加载java类； 系统类加载器：它根据java的类路径来加载类，一般来说，java应用的类都是通过它来加载的； 自定义类加载器：由java语言实现，继承自ClassLoader； 双亲委派模型 当一个类加载器收到一个类加载的请求，他首先不会尝试自己去加载，而是将这个请求委派给父类加载器去加载，只有父类加载器在自己的搜索范围类查找不到给类时，子加载器才会尝试自己去加载该类； 为什么为了防止内存中出现多个相同的字节码； 因为如果没有双亲委派的话，用户就可以自己定义一个java.lang.String类，那么就无法保证类的唯一性； 怎么打破自定义类加载器，继承ClassLoader类，重写loadClass方法和findClass方法； Java 反射 Class getClass() getMethodName()… 对比直接调用速度变慢 123456789101112//正常的调用Apple apple = new Apple();apple.setPrice(5);System.out.println(&quot;Apple Price:&quot; + apple.getPrice());//使用反射调用Class clz = Class.forName(&quot;com.chenshuyi.api.Apple&quot;);Method setPriceMethod = clz.getMethod(&quot;setPrice&quot;, int.class);Constructor appleConstructor = clz.getConstructor();Object appleObj = appleConstructor.newInstance();setPriceMethod.invoke(appleObj, 14);Method getPriceMethod = clz.getMethod(&quot;getPrice&quot;);System.out.println(&quot;Apple Price:&quot; + getPriceMethod.invoke(appleObj)); 原因 反射调用会多出来参数校验的过程 无法被JIT优化，JIT可以帮助java的字节码到原生的机器码层面上，这样的话减少了java字节码的再解析操作，而反射方法是无法被jit优化的 调用过程中的封装与解封操作，invoke 方法的参数是 Object[] 类型，在调用的时候需要进行一次封装。产生了额外的开销 Java 动态代理java动态代理详细用法 通过使用代理，通常有两个优点 优点一：可以隐藏委托类的实现; 优点二：可以实现客户与委托类间的解耦，在不修改委托类代码的情况下能够做一些额外的处理。 HashMap查看详细解读 1.7 1.8区别 拉链法解决hash碰撞时 超过8个链表转红黑树 低于6个转为链表 cpu 占用 100% 在resize的过程中，需要将部分冲突的key迁移至新的桶中 在此过程中，多线程操作可导致链表形成环 ConcurrentHashMap1.7 1.8 区别 1.7采用分段锁 1.8采用synchronized + cas 主要是因为sychronized在jvm上进行了优化，把起步重量级锁，改为从偏向锁开始起步，再到轻量级锁，直到最后才膨胀为重量级锁，极大优化了执行效率，减少了锁的开销 ArrayList扩容机制 初始大小为10，每次扩容增加自身大小的一半 newCap=oldCap+(oldCap&gt;&gt;1) 多线程Synchronized 同步普通方法，锁的是当前对象。 同步静态方法，锁的是当前 Class 对象。 同步块，锁的是 () 中的对象。 synchronized 很多都称之为重量锁，JDK1.6 中对 synchronized 进行了各种优化，为了能减少获取和释放锁带来的消耗引入了偏向锁和轻量锁。 CAS（乐观） 通过原子性来保证数据的同步，比如说数据库的乐观锁，通过版本控制来实现等，所以CAS不会保证线程同步。乐观的认为在数据更新期间没有其他线程影响 优点 非阻塞的轻量级的乐观锁，通过CPU指令实现，在资源竞争不激烈的情况下性能高，相比synchronized重量锁，synchronized会进行比较复杂的加锁，解锁和唤醒操作。 缺点 ABA问题 线程C、D,线程D将A修改为B后又修改为A,此时C线程以为A没有改变过，java的原子类AtomicStampedReference，通过控制变量值的版本来保证CAS的正确性。 自旋时间过长，消耗CPU资源， 如果资源竞争激烈，多线程自旋长时间消耗资源。 线程池（4种类型，拒绝策略） Executors.newCachedThreadPool()：无限线程池。 Executors.newFixedThreadPool(nThreads)：创建固定大小的线程池。 Executors.newSingleThreadExecutor()：创建单个线程的线程池。 newScheduledThreadPool() 创建一个定长线程池，支持定时及周期性任务执行。 优点 减少了创建和销毁线程的次数，每个工作线程都可以被重复利用，可执行多个任务。 可以根据系统的承受能力，调整线程池中工作线线程的数目，防止因为消耗过多的内存，而把服务器累趴下(每个线程需要大约1MB内存，线程开的越多，消耗的内存也就越大，最后死机)。 123456ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler) corePoolSize 为线程池的基本大小。 maximumPoolSize 为线程池最大线程大小。 keepAliveTime 和 unit 则是线程空闲后的存活时间。 workQueue 用于存放任务的阻塞队列。 handler 当队列和最大线程池都满了之后的饱和策略。 线程池的5种状态 RUNNING ：能接受新提交的任务，并且也能处理阻塞队列中的任务； SHUTDOWN：关闭状态，不再接受新提交的任务，但却可以继续处理阻塞队列中已保存的任务。在线程池处于 RUNNING 状态时，调用 shutdown()方法会使线程池进入到该状态。（finalize() 方法在执行过程中也会调用shutdown()方法进入该状态）； STOP：不能接受新任务，也不处理队列中的任务，会中断正在处理任务的线程。在线程池处于 RUNNING 或 SHUTDOWN 状态时，调用 shutdownNow() 方法会使线程池进入到该状态； TIDYING：如果所有的任务都已终止了，workerCount (有效线程数) 为0，线程池进入该状态后会调用 terminated() 方法进入TERMINATED 状态。 TERMINATED：在terminated() 方法执行完后进入该状态，默认terminated()方法中什么也没有做。 ThreadLocal 每个线程中都有一个ThreadLocalMap数据结构，当执行set方法时，其值是保存在当前线程的threadLocals变量中，当执行set方法中，是从当前线程的threadLocals变量获取 123456789static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; { /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) { super(k); value = v; }} 当使用ThreadLocal保存一个value时，会在ThreadLocalMap中的数组插入一个Entry对象，在ThreadLocalMap的实现中，key被保存到了WeakReference对象中。 这就导致ThreadLocal在没有外部强引用时，发生GC时会被回收，如果创建ThreadLocal的线程一直持续运行，那么这个Entry对象中的value就有可能一直得不到回收，发生内存泄露。 StringBuilder 和 StringBuffer StringBuffer线程安全，StringBuilder线程不安全 StringBuilder的效率比StringBuffer高一些 字符串连接操作中StringBuffer的效率要比String高: 12String str = new String(&quot;hello &quot;);str += &quot;world&quot;; 以上代码的处理步骤实际上是通过建立一个StringBuffer 然后调用append(),最后再将StringBuffer toSting(); 这样的话String的连接操作就比StringBuffer多出了一些附加操作,当然效率上要打折扣. SpringBoot相关设计模式代理 动态代理 AOP JDK代理和Cglib代理 观察者 ApplicationEvent ApplicationListener ApplicationEventPublisher 适配器 DispatcherServlet Handler Controller 单例 Bean Component 工厂 BeanFactory DataSourceFactory 模板 JdbcTemplate HibernateTemplate 装饰器 InputStream Wrapper 上下文 ApplicationContext 区别Spring Spring Boot基本上是Spring框架的扩展，它消除了设置Spring应用程序所需的XML配置，为更快，更高效的开发生态系统铺平了道路。 创建独立的Spring应用。 嵌入式Tomcat、Jetty、 Undertow容器（无需部署war文件）。 提供的starters 简化构建配置 尽可能自动配置spring应用。 提供生产指标,例如指标、健壮检查和外部化配置 完全没有代码生成和XML配置要求","link":"/2020/09/06/java-review/"},{"title":"博客图床升级 HTTPS","text":"今天更新一篇博客时发现图片显示不出来了 F12 发现是 github.io 限制图片需要 https 才能访问 被迫升级下图床到 https，好在还有免费证书 Let’s Encrypt 用，太强了 安装 acme.sh123curl https://get.acme.sh | sh# 或者wget -O - https://get.acme.sh | sh Standalone 模式12345# 确保你的 80 端口未被占用，域名自己写，可以添加多个acme.sh --issue -d exp.example.com --standalone# 使用 443 端口acme.sh --issue -d exp.example.com --standalone --tls DNS 手动模式12# 手动执行acme.sh --issue --dns --yes-I-know-dns-manual-mode-enough-go-ahead-please -d www.example.com 12# 手动添加 txt 到域名控制台以后acme.sh --renew --yes-I-know-dns-manual-mode-enough-go-ahead-please -d www.example.com 添加证书到七牛云 Aliyun 自动模式123456# 设置环境变量export Ali_Key=&quot;foo&quot;export Ali_Secret=&quot;bar&quot;# 使用 aliyun dns 自动更新证书acme.sh --issue --dns dns_ali -d www.example.com 将证书部署到七牛123456# 设置环境变量export QINIU_AK=&quot;foo&quot;export QINIU_SK=&quot;bar&quot;# 运行 acme.sh 命令部署到七牛acme.sh --deploy -d www.example.com --deploy-hook qiniu 定时脚本12345# acme.sh 已经创建了定时任务，会定期更新证书10 0 * * * &quot;/root/.acme.sh&quot;/acme.sh --cron --home &quot;/root/.acme.sh&quot; &gt; /dev/null# 设置每月1号执行0 0 1 * * &quot;/root/.acme.sh&quot;/acme.sh --deploy -d www.example.com --deploy-hook qiniu --home &quot;/root/.acme.sh&quot; &gt; /dev/null","link":"/2020/09/14/pic-server-upgrade-https/"},{"title":"PVE 下安装 Openwrt 软路由","text":"本文主要是想在 PVE 环境下打造一个 All in One 的小主机，这一部分是软路由部分，毕竟做开发对 Google Github 之列的需求比较大， Openwrt 的终极目标：出国留学 下载 Openwrt 镜像从恩山下载高大全Openwrt x86软路由固件 https://www.right.com.cn/forum/thread-4059320-1-1.html ，这个固件包括了出国留学的功能，很关键~ PVE 下安装新建一台虚拟机，主要设置如下： 选择刚创建完成的虚拟机，将原来的硬盘分离，并删除 123# 将下载的 openwrt img 文件拷贝到 pve 中，执行如下命令# 100 为虚拟机 id，可以根据实际情况修改qm importdisk 100 openwrt-x86-64-generic-squashfs-combined.img local-lvm 安装完成后，默认地址为 192.168.1.1，账号密码为 root：password，后面可以对网段进行设置 Openwrt 下配置 Docker 这一步是为 docker 分配空间，不然固件刷完后，内存太少，只有几百兆 在侧边栏中选择Docker-&gt;概览 ，关闭Docker 在侧边栏中选择系统-&gt;磁盘管理 分区格式设置为MBR 挂载选择sdb挂载点设置为/opt 然后重新启用 Docker 就设置完成了 Openwrt 设置 AdguardHome AdguardHome 是一个 DNS 服务器，防止 DNS 污染，加速 DNS 查询速度，还能对域名进行 blacklist，也可以用于去广告 123456789101112131415161718192021# 主要端口为 53，3000# 53 端口提供 dns 查询服务# 3000 端口是固件 web ui 默认的端口# adg 访问国内的网络docker run --name adg \\ -v /opt/docker-data/adg/work:/opt/adguardhome/work \\ -v /opt/docker-data/adg/conf:/opt/adguardhome/conf \\ -p 3053:53/tcp \\ -p 3053:53/udp \\ -p 3080:3000/tcp \\ -d adguard/adguardhome# adg-ssr 访问国外的网络docker run --name adg-ssr \\ -v /opt/docker-data/adg-ssr/work:/opt/adguardhome/work \\ -v /opt/docker-data/adg-ssr/conf:/opt/adguardhome/conf \\ -p 5335:53/tcp \\ -p 5335:53/udp \\ -p 3090:3000/tcp \\ -d adguard/adguardhome 访问 http://192.168.1.1:3000 进入 Web UI 中，进行首次设置 进入 Openwrt 中，对网络-&gt;DHCP/DNS进行设置，DNS 转发设置为：127.0.0.1：3053 Adguard Home 设置1234567891011121314# DNS 设置tls://8.8.8.8tls://8.8.4.4tls://dns.googlehttps://dns.google/dns-querytls://208.67.222.222tls://208.67.220.220https://doh.opendns.com/dns-query# Bootstrap DNS208.67.222.2228.8.8.88.8.4.41.1.1.1 名称 简介 地址 AdGuard DNS Filter AdGuard 官方维护的广告规则，涵盖多种过滤规则 https://raw.githubusercontent.com/AdguardTeam/FiltersRegistry/master/filters/filter_15_DnsFilter/filter.txt EasyList Adblock Plus 官方维护的广告规则 https://easylist-downloads.adblockplus.org/easylist.txt EasyList China 面向中文用户的 EasyList 去广告规则 https://easylist-downloads.adblockplus.org/easylistchina.txt EasyPrivacy 反隐私跟踪、挖矿规则 https://easylist-downloads.adblockplus.org/easyprivacy.txt Halflife 规则 涵盖了 EasyList China、EasyList Lite、CJX ’s Annoyance、乘风视频过滤规则，以及补充的其它规则 https://gitee.com/halflife/list/raw/master/ad.txt Xinggsf 乘风过滤 国内网站广告过滤规则 https://gitee.com/xinggsf/Adblock-Rule/raw/master/rule.txt Xinggsf 乘风视频过滤 视频网站广告过滤规则 https://gitee.com/xinggsf/Adblock-Rule/raw/master/mv.txt MalwareDomainList 恶意软件过滤规则 https://www.malwaredomainlist.com/hostslist/hosts.txt Adblock Warning Removal List 去除禁止广告拦截提示规则 https://easylist-downloads.adblockplus.org/antiadblockfilters.txt Anti-AD 命中率高、兼容性强 https://anti-ad.net/easylist.txt Fanboy’s Annoyances List 去除页面弹窗广告规则 https://easylist-downloads.adblockplus.org/fanboy-annoyance.txt 出国留学","link":"/2021/03/27/pve-openwrt/"},{"title":"PVE 使用与硬件直通","text":"Proxmox虚拟环境（简称PVE）是用于操作来宾操作系统的基于 Debian 和 KVM 的虚拟化平台。 PVE 安装下载并烧录下载iso文件后，烧录到u盘中 https://www.proxmox.com/en/downloads 如果要在虚拟机中配置openwrt，建议断网安装 设置你希望用来管理pve的网卡，和网段，我一般都是192.168.1.1、192.168.10.1、192.168.100.1这几个网段 PVE 更新源123456789101112vi /etc/apt/sources.list.d/pve-no-subscription.list # 添加deb http://download.proxmox.com/debian/pve buster pve-no-subscription# 或者echo &quot;deb http://download.proxmox.com/debian/pve buster pve-no-subscription&quot; &gt; /etc/apt/sources.list.d/pve-no-subscription.list # 注释 pve-enterprise.listvi /etc/apt/sources.list.d/pve-enterprise.list# deb https://enterprise.proxmox.com/debian/pve buster pve-enterpriseapt updateapt install -y vim git net-tools PVE 直通grub文件修改1234567891011121314# 编辑grub文件vim /etc/default/grub# 开启IOMMU，intelGRUB_CMDLINE_LINUX_DEFAULT=&quot;quiet intel_iommu=on&quot;# 开启IOMMU，amdGRUB_CMDLINE_LINUX_DEFAULT=&quot;quiet amd_iommu=on&quot;# 希望核显直通，再加个 video=efifb:offGRUB_CMDLINE_LINUX_DEFAULT=&quot;quiet intel_iommu=on video=efifb:off&quot;# 分组直通 pcie_acs_override=downstreamGRUB_CMDLINE_LINUX_DEFAULT=&quot;quiet intel_iommu=on pcie_acs_override=downstream&quot;#更新grubupdate-grub 系统模块修改123456789101112131415161718192021# 添加系统模块echo &quot;vfio&quot; &gt;&gt; /etc/modulesecho &quot;vfio_iommu_type1&quot; &gt;&gt; /etc/modulesecho &quot;vfio_pci&quot; &gt;&gt; /etc/modulesecho &quot;vfio_virqfd&quot; &gt;&gt; /etc/modules# 添加模块黑名单# 核显echo &quot;blacklist snd_hda_intel&quot; &gt;&gt; /etc/modprobe.d/pve-blacklist.confecho &quot;blacklist snd_hda_codec_hdmi&quot; &gt;&gt; /etc/modprobe.d/pve-blacklist.confecho &quot;blacklist i915&quot; &gt;&gt; /etc/modprobe.d/pve-blacklist.conf# 独显echo &quot;blacklist nouveau&quot; &gt;&gt; /etc/modprobe.d/pve-blacklist.confecho &quot;blacklist radeon&quot; &gt;&gt; /etc/modprobe.d/pve-blacklist.conf# N卡需要额外添加echo &quot;options kvm ignore_msrs=1&quot; &gt; /etc/modprobe.d/kvm.conf# 更新内核update-initramfs -u -k all# 重启后，pve直连显示器无输出reboot 屏蔽需要直通的设备123456789101112131415161718192021# 检查模块信息lsmod | grep vfio# 回显，直通正常vfio_pci 53248 0vfio_virqfd 16384 1 vfio_pciirqbypass 16384 12 vfio_pci,kvmvfio_iommu_type1 32768 0vfio 32768 2 vfio_iommu_type1,vfio_pci# 查看显卡设配IDlspci -nn | grep VGA# 回显，本人i3 10100核显代号8086:9bc800:02.0 VGA compatible controller [0300]: Intel Corporation Device [8086:9bc8] (rev 03)# 查看 00:02.0 设备占用情况lspci -vvv -s 00:02.0# 如下显示表示核显直通正常Kernel driver in use: vfio-pciKernel modules: i915# 把需要直通给虚拟机的设备ID写到vfio.confecho &quot;options vfio-pci ids=8086:9bc8&quot; &gt;&gt; /etc/modprobe.d/vfio.conf 选择虚拟机-&gt;硬件-&gt;添加-&gt;pci设备 RTL8125B 网卡驱动GitHub 驱动安装脚本 https://github.com/tubaxiaosiji/RTL8125-Driver-for-Proxmox-VE5-6-and-debian 官网最新驱动 https://www.realtek.com/en/component/zoo/category/network-interface-controllers-10-100-1000m-gigabit-ethernet-pci-express-software","link":"/2020/12/29/pve-tutorial/"},{"title":"手撕雪花 Snow Flake","text":"分布式系统中，有一些需要使用全局唯一ID的场景，这种时候为了防止ID冲突可以使用36位的UUID，但是UUID有一些缺点，首先他相对比较长，另外UUID一般是无序的。有些时候我们希望能使用一种简单一些的ID，并且希望ID能够按照时间有序生成。而twitter的snowflake解决了这种需求，最初Twitter把存储系统从MySQL迁移到Cassandra，因为Cassandra没有顺序ID生成机制，所以开发了这样一套全局唯一ID生成服务。 理论说明 能满足高并发分布式系统环境下ID不重复 基于时间戳，可以保证基本有序递增（有些业务场景对这个又要求） 不依赖第三方的库或者中间件 生成效率极高 1位，不用。二进制中最高位为1的都是负数，但是我们生成的id一般都使用整数，所以这个最高位固定是0 41位，用来记录时间戳（毫秒）。41位可以表示2^41−1个数字，因为要保证自增，不允许回调时间！ 10位，用来记录工作机器ID。 可以部署在2^10=1024个节点 12位，序列号，用来记录同毫秒内产生的不同id。 12位可以表示的最大正整数是2^12−1=4095，来表示同一机器同一时间截（毫秒)内产生的4095个ID序号 额外的，可以在这41+10+12位中，取出一些连续的位，设置为特别需求的标志位，如业务ID啥的 12345678 1L == 0000 0000 0000 0001-1L == 1111 1111 1111 1111，-1 的补码 为 1 的 反码 +1-1L &lt;&lt; MACHINE_SHIFT：-1 左移 10 位：高位舍弃，低位用 0 补齐，为 1111 1100 0000 0000则： 1111 1111 1111 1111^ 1111 1100 0000 0000---------------------= 0000 0011 1111 1111 补充说明 当进入下一毫秒时，序列号不应直接置0，因为如果一个业务量恰好1ms生成一次，那出现的结果均为偶数，不利于分库分表，可以根据时间奇偶性，来设定 0 或 1 来改善奇偶性 项目的 START_STAMP 是不允许会退的，因为要保证 ID 自增且唯一，如果回退了，有可能会出现重复 ID，当发现时间回退时，应抛出异常 当同一毫秒生成数达到最大值时，不能继续生成，否则序列号必然重复，需要自旋等待下一毫秒 Java 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109package vip.housir;/** * @author housirvip */public class SnowFlake { /** * 起始的时间戳, 2020-09-14 17:08:33 * 为保证id递增，不允许回退！！！ */ private final static long START_STAMP = 1600074513000L; /** * 序列号占用的长度 */ private final static int SERIAL_LEN = 12; /** * 机器标识占用的长度 */ private final static int MACHINE_LEN = 10; /** * 最大支持的机器数量 * -1L ^ (-1L &lt;&lt; MACHINE_LEN) * 或者 * ~(-1L &lt;&lt; MACHINE_LEN) */ private final static long MAX_MACHINE = -1L ^ (-1L &lt;&lt; MACHINE_LEN); /** * 用位运算计算出12位能存储的最大正整数：4095 */ private final static long MAX_SERIAL = -1L ^ (-1L &lt;&lt; SERIAL_LEN); /** * 机器标志的偏移量 */ private final static int MACHINE_SHIFT = SERIAL_LEN; /** * 时间戳的偏移量 */ private final static int TIMESTAMP_SHIFT = MACHINE_LEN + SERIAL_LEN; private long serialNum = 0L; private long lastTimeStamp = -1L; private final int machineId; public SnowFlake(int machineId) { // MachineID 越界 if (machineId &gt; MAX_MACHINE) { throw new RuntimeException(&quot;Machine ID out of the range, MAX_MACHINE: &quot; + MAX_MACHINE); } this.machineId = machineId; } /** * 产生下一个ID * * @return 新的雪花ID */ public synchronized long generateId() { // 获取当前时间戳 long curStamp = getNewStamp(); // 如果当前时间戳小于上次时间戳则抛出异常 if (curStamp &lt; lastTimeStamp) { throw new RuntimeException(&quot;Clock moved backwards. Refusing to generate id&quot;); } // 相同毫秒内 if (curStamp == lastTimeStamp) { // 相同毫秒内，序列号自增 serialNum = (serialNum + 1) &amp; MAX_SERIAL; // 同一毫秒的序列数已经达到最大 if (serialNum == 0L) { //自旋，等待下一毫秒 curStamp = waitNextMill(); } } else { // 不同毫秒内，序列号置为初始值，0L或者1L，防止出现全为偶数的情况 serialNum = curStamp &amp; 1; } //当前时间戳存档记录，用于下次产生id时对比是否为相同时间戳 lastTimeStamp = curStamp; return ((curStamp - START_STAMP) &lt;&lt; TIMESTAMP_SHIFT) | (machineId &lt;&lt; MACHINE_SHIFT) | serialNum; } private long waitNextMill() { long mill = getNewStamp(); //自旋，等待下一毫秒 while (mill &lt;= lastTimeStamp) { mill = getNewStamp(); } return mill; } private long getNewStamp() { return System.currentTimeMillis(); }}","link":"/2020/09/14/snow-flake/"},{"title":"Ubuntu 下安装 Docker 和 Portainer","text":"卸载原有的 docker 组件1sudo apt-get remove docker docker-engine docker.io containerd runc 安装依赖1234# 更新aptsudo apt-get update# 安装依赖sudo apt-get install -y apt-transport-https ca-certificates curl gnupg lsb-release 安装 Docker123456789# Add Docker’s official GPG keycurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg# set up the stable repositoryecho &quot;deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot; | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null# 更新 apt 并安装 dockersudo apt-get updatesudo apt-get install docker-ce docker-ce-cli containerd.io 安装 Portainer Portainer 是 docker 的一个可视化操作界面，用起来比较方便 1234sudo docker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -v /home/housirvip/docker/portainer:/data \\ portainer/portainer-ce","link":"/2021/03/25/ubuntu-docker/"},{"title":"Zerotier 组网，访问路由器内网","text":"介绍ZeroTier 这一类 P2P VPN 是在互联网的基础上将自己的所有设备组成一个私有的网络，可以理解为互联网连接的局域网。最常见的场景就是在公司可以用手机直接访问家里的 NAS，而且是点对点直连，数据传输并不经由第三方服务器中转。 Zerotier 在多设备之间建立了一个 Peer to Peer VPN（P2PVPN） 连接，如：在笔记本电脑、台式机、嵌入式设备、云资源和应用。这些设备只需要通过 ZeroTier One ( ZeroTier 的客户端) 在不同设备之间建立直接连接，即使它们位于 NAT 之后。连接到虚拟 LAN 的任何计算机和设备通常通过 NAT 或路由器设备与 Internet 连接，ZeroTier One 使用 STUN 和隧道来建立 NAT 后设备之间的 VPN 直连。 开始操作 如果没有账号请先注册 点击 Create A Network，创建一个网段 设置 Managed Routes 进入 Openwrt 路由器中，开启 Zerotier 并开启 NAT 回到 Zerotier 网页，设定设备地址，并勾选 Auth 设置完成正常情况这样就设置完成了 1234567891011121314➜ ~ ping 192.168.192.110PING 192.168.192.110 (192.168.192.110): 56 data bytes64 bytes from 192.168.192.110: icmp_seq=0 ttl=63 time=544.825 ms64 bytes from 192.168.192.110: icmp_seq=1 ttl=63 time=479.400 ms64 bytes from 192.168.192.110: icmp_seq=2 ttl=63 time=471.522 ms64 bytes from 192.168.192.110: icmp_seq=3 ttl=63 time=510.082 ms64 bytes from 192.168.192.110: icmp_seq=4 ttl=63 time=426.459 ms64 bytes from 192.168.192.110: icmp_seq=5 ttl=63 time=557.033 ms64 bytes from 192.168.192.110: icmp_seq=6 ttl=63 time=499.948 ms64 bytes from 192.168.192.110: icmp_seq=7 ttl=63 time=575.980 ms64 bytes from 192.168.192.110: icmp_seq=8 ttl=63 time=486.583 ms--- 192.168.192.110 ping statistics ---15 packets transmitted, 10 packets received, 33.3% packet lossround-trip min/avg/max/stddev = 426.459/510.064/575.980/43.965 ms 补充说明如果路由器固件不带 Zerotier，需要自己配置路由器网络转发 创建新接口，并设置接口名称，关联网卡信息 设置防火请 123iptables -I FORWARD -i zt2lrwm2qj -j ACCEPTiptables -I FORWARD -o zt2lrwm2qj -j ACCEPTiptables -t nat -I POSTROUTING -o zt2lrwm2qj -j MASQUERADE","link":"/2021/03/25/zerotier/"},{"title":"Docker+Consul服务发现","text":"前言Docker从入门到实践细节部分讲的不是特别细，很多知识还是得各种查资料。 Docker文档 consul文档如果你选择 Consul，这个是必读的 consul的docker镜像包装 Consul 的镜像，简化了 Consul 的部署 架构 首先架构应该是，简单的，可迭代演进的。这样可操作性和可维护性会更强。 谈架构，无外乎就是高可用和可扩展，脱离这两个都是耍流氓。还有就是省钱，动不动20台服务器，创业公司伤不起。所以，解决好了就是好架构。 监控方案是后续迭代演进的事，你必须要保证你的系统正常运转，才能缩短开发周期。留出更多的时间，你可以做这些重要的事。 关于负载均衡器，有很多备选方案，现在云服务这么发达，可选的方案也很多，甚至有跨机房的负载均衡。比自己搭 nginx+keepalived 要方便的多。 选择 Consul ，用于服务发现，解决的是服务互访的问题。 架构原理第一步，所有应用启动之后会向 Consul 集群注册自己，注册的信息包括 所属数据中心 DC1 所属数据中心的宿主机节点 所属节点的服务，服务访问方式 ip ，端口 应用在启动的时候往 Consul 注册Api发送注册服务信息。后期 Consul 会负责服务节点的健康检查。 第二步，当应用间存在访问时，如 Api 网关访问微服务，Web应用访问微服务，微服务之间互访。这里可以使用Consul Api 定期请求服务状态的方式，来获取可用的节点，后面会详细介绍。请求到节点后还可以在应用程序级别做一些负载均衡策略。 安装虚拟机VirtualBox 作为实验性项目，使用 VirutalBox 可以快速构建你想要的物理环境，而且 Docker和 Virtualbox 搭配的很好，使用 Docker-machine 可以非常简单的管理所有虚拟机。 开始好了，万事具备。现在我们开始创建虚拟机。 使用 Docker 工具包自带的 Docker-machine 工具，可以帮你快速创建一个 Docker 宿主机。 在这个架构中，我们一共只需要创建 3 台宿主机 Docker-machine 命令后面会用的比较频繁，所以我们改个短点的名字。 这里我用 zsh，bash 类似。 123$ vi ~/.zshrc#增加alias dm=&quot;docker-machine&quot; 依次创建3台虚拟机 123$ dm create -d &quot;virtualbox&quot; node1$ dm create -d &quot;virtualbox&quot; node2$ dm create -d &quot;virtualbox&quot; node3 ip 是自动分配的，不出意外的话，会得到下面对应的 ip（如果真出意外了，就改改 ip 吧） $ dm ls 1234NAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORSnode1 - virtualbox Running tcp://192.168.99.100:2376 v17.06.0-cenode2 - virtualbox Running tcp://192.168.99.101:2376 v17.06.0-cenode3 - virtualbox Running tcp://192.168.99.102:2376 v17.06.0-ce 配置 Consul Server宿主机 node1 我们新开一个终端 $ dm ssh node1 启动第一台 Consul Server，非常简单，一条命令搞定 1234567891011$ docker run -h node1 --name consul -d -v /data:/data --restart=always \\ -p 8300:8300 \\ -p 8301:8301 \\ -p 8301:8301/udp \\ -p 8302:8302 \\ -p 8302:8302/udp \\ -p 8400:8400 \\ -p 8500:8500 \\progrium/consul -server \\-bootstrap-expect 3 \\-advertise 192.168.99.100 下面来解释下各个参数 -h 节点名字 —name 容器（container）名称，后期用来方便启动关闭，看日志等，这个一定要写 -d 后台运行 -v /data:/data 使用宿主机的 /data 目录映射到容器内部的 /data,用于保存 Consul 的注册信息，要不 Docker 一重启，数据是不保留的。 --restart=always 这个可以活得长一点 下面几个参数都是 Consul 集群用的，非集群模式可以不使用。 1234-p 8301:8301 -p 8301:8301/udp -p 8302:8302 -p 8302:8302/udp progrium/consul 镜像名称，本地没有就自动从公共 Docker 库下载 后面的都是 Consul 的参数： -server 以服务节点启动 -bootstrap-expect 3 预期的启动节点数 3，最少是 3，要不达不到 Cluster 的效果，如果只有一台机器的话可以修改 3 为 1 -advertise 192.168.99.100 告诉集群，我的 ip 是什么，就是注册集群用的 执行完毕后 ，使用 docker ps 看下，是否运行正常。docker logs 就不用看了，里面各种警告和错误，其实那都是假象。 但是 Consul Cluster 你必须明白，只有3个 Consul Server 节点都启动正常了，整个集群才能正常启动。 配置下一台 Consul Server开启一个新的终端 12345678910111213141516171819202122$ dm ssh node2 #进入 node2 宿主机$ docker run -h node2 --name consul -d -v /data:/data --restart=always \\ -p 8300:8300 \\ -p 8301:8301/udp \\ -p 8302:8302 \\ -p 8302:8302/udp \\ -p 8400:8400 \\ -p 8500:8500 \\progrium/consul -server \\-advertise 192.168.99.101 \\-join 192.168.99.100$ dm ssh node3 #进入 node3 宿主机$ docker run -h node3 --name consul -d -v /data:/data --restart=always \\ -p 8300:8300 \\ -p 8301:8301/udp \\ -p 8302:8302 \\ -p 8302:8302/udp \\ -p 8400:8400 \\ -p 8500:8500 \\progrium/consul -server \\-advertise 192.168.99.102 \\-join 192.168.99.100 这里多了一个参数-join 192.168.99.100 代表的是加入 node1 建立好的 Consul Server Consul 配置完毕检查是否成功，没出意外的话，就看到下面的界面 http://192.168.99.100:8500 总结总的来说，这个已经算是极简的架构了。当然，docker的生命周期远不止这些，比如ci，发布上线，灰度发布等。docker远没有传说中那么简单，美妙。docker有很多的好处，但是需要DevOPS做很多的工作。 在实践过程中，我发现有一个或许是更优的架构。那就是seneca的方案，使用事件相应作为微服务的提供方式，这样就避免了服务发现这件事，完全不需要注册服务，选择服务这么麻烦。也不用为服务发现服务搭建一个集群确保其高可用。","link":"/2018/05/20/Docker-Consul%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/"},{"title":"Docker常见命令与操作","text":"Docker 命令入门拉取镜像docker pull &lt;镜像名:tag&gt; 例如 docker pull progrium/consul:latest 列出存在的镜像docker images 结果显示举例 1234REPOSITORY TAG IMAGE ID CREATED SIZEswaggerapi/swagger-editor latest aaa304fc1b89 2 months ago 35.9MBdaocloud.io/library/ubuntu 16.04 14f60031763d 10 months ago 120MBprogrium/consul latest 09ea64205e55 2 years ago 69.4MB 删除镜像docker rmi &lt;镜像名&gt; docker rmi $(docker images | grep none | awk '{print $3}' | sort -r) 删除所有镜像 创建容器docker run -t -i ubuntu:16.04 /bin/bash docker run -d -p 80:80 -v /data:/data --name ubuntu ubuntu:16.04 /bin/bash --name 参数可以指定启动后的容器名字，如果不指定则docker会帮我们取一个名字 -i -t 立即进入到容器命令行操作，其中，-t 选项让Docker分配一个伪终端（pseudo-tty）并绑定到容器的标准输入上， -i 则让容器的标准输入保持打开。 后台运行可以填写 -d -p &lt;host_port:contain_port&gt; 是端口暴露或者端口映射 1234-p 11211:11211 这个即是默认情况下，绑定主机所有网卡（0.0.0.0）的11211端口到容器的11211端口上-p 127.0.0.1:11211:11211 只绑定localhost这个接口的11211端口-p 127.0.0.1::5000-p 127.0.0.1:80:8080 -v &lt;host_path:container_path&gt; 是目录映射 操作容器查看正在运行的容器docker ps docker ps -a 为查看所有的容器，包括已经停止的 启动关闭和重启1234docker start &lt;container_id_or_name&gt;docker stop &lt;container_id_or_name&gt;docker restart &lt;container_id_or_name&gt;docker kill &lt;container_id_or_name&gt; 进入到正在运行的容器docker exec -it &lt;container_id_or_name&gt; /bin/bash 操作完成后，直接 ctrl + d 或者直接输入 exit 退出即可 删除容器docker rm &lt;container_id_or_name&gt; 查看容器user密码docker logs &lt;container_id_or_name&gt; 2&gt;&amp;1 | grep '^User: ' | tail -n1 因为docker容器启动时的root用户的密码是随机分配的。所以，通过这种方式就可以得到redmine容器的root用户的密码了 查看容器日志docker logs -f &lt;container_id_or_name&gt; Docker 进阶操作 详见 Gitbook Docker从入门到实践 修改Docker本地镜像与容器的存储位置方法一、软链接默认情况下Docker的存放位置为：/var/lib/docker 可以通过下面命令查看具体位置： 1sudo docker info | grep &quot;Docker Root Dir&quot; 解决这个问题，最直接的方法当然是挂载分区到这个目录，但是我的数据盘还有其他东西，这肯定不好管理，所以采用修改镜像和容器的存放路径的方式达到目的 这个方法里将通过软连接来实现 首先停掉Docker服务： 123systemctl restart docker或者service docker stop 然后移动整个/var/lib/docker目录到目的路径： 12mv /var/lib/docker /root/data/dockerln -s /root/data/docker /var/lib/docker 这时候启动Docker时发现存储目录依旧是/var/lib/docker，但是实际上是存储在数据盘的，你可以在数据盘上看到容量变化 方法二、修改镜像和容器的存放路径指定镜像和容器存放路径的参数是--graph=/var/lib/docker，我们只需要修改配置文件指定启动参数即可。 Docker 的配置文件可以设置大部分的后台进程参数，在各个操作系统中的存放位置不一致，在 Ubuntu 中的位置是：/etc/default/docker，在 CentOS 中的位置是：/etc/sysconfig/docker。 如果是 CentOS 则添加下面这行： 1OPTIONS=--graph=&quot;/root/data/docker&quot; --selinux-enabled -H fd:// 如果是 Ubuntu 则添加下面这行（因为 Ubuntu 默认没开启 selinux）： 123OPTIONS=--graph=&quot;/root/data/docker&quot; -H fd://# 或者DOCKER_OPTS=&quot;-g /root/data/docker&quot; 最后重新启动，Docker 的路径就改成 /root/data/docker 了 生成新的 imagebuild命令可以从Dockerfile和上下文来创建镜像：docker build [OPTIONS] PATH | URL | -上面的PATH或URL中的文件被称作上下文，build image的过程会先把这些文件传送到docker的服务端来进行的如果PATH直接就是一个单独的Dockerfile文件则可以不需要上下文；如果URL是一个Git仓库地址，那么创建image的过程中会自动git clone一份到本机的临时目录，它就成为了本次build的上下文。无论指定的PATH是什么，Dockerfile是至关重要的，请参考 Dockerfile Reference。请看下面的例子： 123456789101112131415161718# cat Dockerfile FROM seanlook/nginx:bash_vimEXPOSE 80ENTRYPOINT /usr/sbin/nginx -c /etc/nginx/nginx.conf &amp;&amp; /bin/bash# docker build -t seanlook/nginx:bash_vim_Df .Sending build context to Docker daemon 73.45 MBSending build context to Docker daemon Step 0 : FROM seanlook/nginx:bash_vim ---&gt; aa8516fa0bb7Step 1 : EXPOSE 80 ---&gt; Using cache ---&gt; fece07e2b515Step 2 : ENTRYPOINT /usr/sbin/nginx -c /etc/nginx/nginx.conf &amp;&amp; /bin/bash ---&gt; Running in e08963fd5afb ---&gt; d9bbd13f5066Removing intermediate container e08963fd5afbSuccessfully built d9bbd13f5066 给镜像打上标签tag 的作用主要有两点：一是为镜像起一个容易理解的名字，二是可以通过docker tag来重新指定镜像的仓库，这样在push时自动提交到仓库。 12345# 将同一IMAGE_ID的所有tag，合并为一个新的docker tag 195eb90b5349 seanlook/ubuntu:rm_test# 新建一个tag，保留旧的那条记录docker tag Registry/Repos:Tag New_Registry/New_Repos:New_Tag","link":"/2018/05/20/Docker%E5%B8%B8%E8%A7%81%E5%91%BD%E4%BB%A4%E4%B8%8E%E6%93%8D%E4%BD%9C/"},{"title":"搭建纯净 DNS 服务","text":"起因 国内近年来 DNS 污染严重，甚至就连一些地方宽带商都胡乱投毒，整一些花里胡哨的广告页面，什么，你想要干净清爽的网络浏览？ 经过安装开发环境1sudo apt-get install git build-essential cmake -y 一般的 ubuntu 和 debian 系统都可以做到，但是我之前用的 ubuntu mate 会报错，找不到 build-essential，那么使用 aptitude 来解决依赖项 12sudo apt-get install aptitude -ysudo aptitude install build-essential -y 安装依赖项 这里列举下一般容易缺少的依赖项 LibPcap Libsodium OpenSSL Flex Bison 这些依赖项可以去选择手动编译，也可以直接 1sudo apt-get install -y libsodium-dev libpcap-dev libssl-dev flex bison 安装 Pcap_DNSProxy12345cdgit clone https://github.com/chengr28/Pcap_DNSProxy.gitcd Pcap_DNSProxy/Source/Auxiliary/Scriptschomd a+x CMake_Build.shsudo ./CMake_Build.sh 编译完成后，生成的程序在Pcap_DNSProxy/Source/Release下，可以选择把这个 cp 到/usr/local/下，我是没改动位置就直接这么用了 123cd cd Pcap_DNSProxy/Source/Releasesudo vi Pcap_DNSProxy.service WorkingDirectory填写你的程序位置文件夹 ExecStart填写程序位置文件夹跟上程序名 1234567[Service]Type=forkingWorkingDirectory=/home/pi/Pcap_DNSProxy/Source/ReleaseExecStart=/home/pi/Pcap_DNSProxy/Source/Release/Pcap_DNSProxyGuessMainPID=yesRestart=on-failureRestartSec=15s 12345sudo ./Linux_Install.Systemd.sh# 以后想重启，关闭什么的sudo service Pcap_DNSProxy restartsudo service Pcap_DNSProxy stopsudo service Pcap_DNSProxy status 结果 dig 命令测试 DNS 回到 123456789101112131415161718192021pi@raspberrypi:~/Pcap_DNSProxy/Source/Release $ dig @127.0.0.1 www.google.com; &lt;&lt;&gt;&gt; DiG 9.10.3-P4-Raspbian &lt;&lt;&gt;&gt; @127.0.0.1 www.google.com; (1 server found);; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 56212;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 512;; QUESTION SECTION:;wwW.GOoGlE.coM. IN A;; ANSWER SECTION:wwW.GOoGlE.coM. 266 IN A 216.58.200.36;; Query time: 241 msec;; SERVER: 127.0.0.1#53(127.0.0.1);; WHEN: Thu Aug 24 06:34:31 UTC 2017;; MSG SIZE rcvd: 59","link":"/2017/08/24/dnscrypt/"},{"title":"在z270平台装黑苹果","text":"动机以前一直在用 win10 最近在开发的几个 web和移动 app 项目，前端是 angular4 或者基于 angular4 的 ionic3，后端是 golang 编写，每次编译的时候，我看着这个进度条，总感觉天空飘来五个字，我特么社保。 后来换到 ubuntu desktop 16.04，感觉编译速度肉眼可见的狂暴提升，好吧既然如此，就不用再等 win10 使出洪荒之力了。 再后来，换了新配置… 准备工作硬件设备 一个 Mac OS 的电脑（最好是这样，win 下麻烦些） 一个 8G U盘，可大不可小 一台 z270 平台待装机电脑 软件工具 Mac OS 操作系统 或者 虚拟机 Clover EFI 最新版 kext 驱动和 config.plist 额外说明 截止到我现在这个时间，Mac OS 10.12.6 已经原生支持 Kaby Lake 平台，终于摆脱了 Sky Lake 的各种 Fake ID 包括 I7-7700 I5-7500 但不仅限于 核心显卡 HD630 也原生支持了 AMD polaris架构虽然早已支持，但一直无法单卡启动的问题通过 Lilu.kext 和 Whaterergreen.kext 解决了 声卡通过 AppleALC.kext 驱动，升级系统就不会掉驱动了 额外安利几篇写的很好的 KabyLake 安装黑苹果的教程，我就看了这几篇就直接开始动手安装，性价比很高的教程，从过程到原理都有介绍到 Guide to installing macOS on a Kabylake Hackintosh for Sierra (10.12.5 Working) Updating your Hackintosh to Sierra 10.12.6 How to hackintosh AMD graphics cards in Sierra 10.12.6+ Building a GTX 1080 Ti-powered Hackintosh: Installing macOS Sierra step-by-step 疯狂操作起来 有条件的先看下这个视频教程，有个了解，歪果仁发在 youtube 上的，如果被墙了看不到就算了，直接看往下文字版吧 制作U盘启动器 在 App Store 中下载 Mac OS Sierra 插入U盘，打开磁盘工具，格式化U盘 请注意，点击主硬件设备，而不是点击某个分区，格式务必为 Mac OS 扩展（日志式），方案 GUID 分区图，抹掉，然后静静地等待 Mac OS Sierra 下载完成 1sudo /Applications/Install\\ macOS\\ Sierra.app/Contents/Resources/createinstallmedia --applicationpath /Applications/Install\\ macOS\\ Sierra.app --volume /Volumes/未命名/ 将系统安装程序拷贝到U盘中，这个过程也挺慢的。拷贝完成后开始安装 Clover EFI 启动器 点击更改安装位置，选择你的U盘 仅安装 UEFI 开机版本 安装 Clover 到 EFI 系统区 Drivers64UEFI &gt; EmuVariableUefi-64 Drivers64UEFI &gt; OsxAptioFix2DrV-64 Drivers64UEFI &gt; PartitionDxe-64 把你刚才下载的 z720-EFI 解压缩，覆盖到U盘刚生成的 EFI 分区中 12如果你是核心显卡用户 Intel iGPU HD530/HD630，请打开 /Volumes/EFI/EFI/CLOVER/修改 config-iGPU.plist 为 config.plist 123如果你是英伟达显卡用户，请打开 /Volumes/EFI/EFI/CLOVER/修改 config-NV.plist 为 config.plist另外下载 [NvidiaGraphicsFixup.kext](https://sourceforge.net/projects/nvidiagraphicsfixup/) 放到 Volumes/EFI/EFI/CLOVER/kext/other/ 下 12如果你是AMD显卡用户，请打开 /Volumes/EFI/EFI/CLOVER/修改 config-AMD.plist 为 config.plist 12如果你是微星主板用户下载 [OsxAptioFix2Drv-free2000.efi.zip](https://cl.ly/020C180S2R32/OsxAptioFix2Drv-free2000.efi.zip)解压 OsxAptioFix2Drv-free2000.efi 到 /Volumes/EFI/EFI/CLOVER/drivers64UEFI/ 下 123如果你是技嘉或者华硕主板用户接下来用 Clover Configurater 打开 config.plist，开始修改一些内容左侧导航栏选择 Acpi 然后勾选 FixShutdown_0004 保存 点击左侧 SMBIOS ，再点击右侧下拉按钮，请按照你的 CPU 进行选择模拟配置Mac型号 保存并重启电脑，进入 BIOS 设置 Save &amp; Exit : Load Optimized Defaults M.I.T. : Advanced Memory Settings → Extreme Memory Profile(X.M.P.) : Profile1 BIOS → Fast Boot : Disabled BIOS → Windows 8/10 Features : Other OS BIOS → LAN PXE Boot Option ROM : Disabled BIOS → Storage Boot Option Control : UEFI Peripherals → Initial Display Output : IGFX or PCIe 1 Slot Peripherals → Super IO Configuration → Serial Port : Disabled Peripherals → Network Stack Configuration → Network Stack : Disabled Peripherals → USB Configuration → XHCI Hand-off : Enabled Chipset → Vt-d : Disabled Chipset → Wake on LAN Enable : Disabled 显卡按照你的实际选择，是IGFX还是PCI1或者是PCI2 按 F10 保存并重启，选择你的U盘进入系统 开始安装系统 先用磁盘工具给自己的硬盘分区，在安装就行了，这几步都没什么坑 这里有点坑，登录 Apple ID 选择否，与苹果分享信息选择否，不然直接蹦系统 进入系统进行配置 把U盘中/Volumes/EFI/EFI/CLOVER/下所有文件复制到电脑上，拔掉U盘 再次安装 Clover EFI 到你的系统硬盘中，又会出现一个 EFI 分区,如果没自动出现，请自行挂载 把刚才拷贝的/EFI/CLOVER/复制到EFI分区下相同目录下 英伟达显卡用户这时候可以去安装 NVDIA Web Driver 了 好了，至此，完蛋。不，完工了 看看效果","link":"/2017/08/18/hackintosh-z270/"},{"title":"KMP算法个人理解","text":"简介 KMP算法是一种改进的字符串匹配算法，由D.E.Knuth，J.H.Morris和V.R.Pratt同时发现，因此人们称它为克努特—莫里斯—普拉特操作（简称KMP算法）。 KMP算法的关键是利用匹配失败后的信息，尽量减少模式串与主串的匹配次数以达到快速匹配的目的。具体实现就是实现一个next()函数，函数本身包含了模式串的局部匹配信息。时间复杂度O(m+n)。 理论介绍设目标字符串target为：a b a c a a b a c a b a c a b a a b b 模式字符串model为：a b a c a b 计算next数组对此model串的next数组计算为[0 0 1 0 1 2]计算规则为：截止到此index，首尾重复的子串最大长度。 a 规定为0 ab 首尾子串a和b，重复长度为0 aba 首部子串a，ab，尾部子串a，ba，重复1 abac 首部子串a，ab，aba，尾部子串c，ac，bac，长度为0 abaca 首部子串a，ab，aba，abac，尾部子串a，ca，aca，baca，长度为1 abacab 首部子串a，ab，aba，abac，abaca，尾部子串b，ab，cab，acab，bacab，长度为2 next数组就是这样子去算，不过从上述过程可以发现，next数组，上次的数值和下次的数值是有所关系的，有三种情况会发生：1.归零；2.归一；3.加一； 归零是加上一位字符后，没有重复首尾没有重复了，甚至首位和尾位单字符都不相同了，就归零。归一是加上加上一位字符后，只剩下首位和尾位单字符相同。加一是加上一位字符后，碰巧和首部那串字符相同顺序，多一个字符，就是多的那一个子串的长度。 举个例子对于字符串abcabcadnext[0]=0next[1]=0next[2]=0next[3]=0+1next[4]=1+1next[5]=2+1next[6]=1next[7]=0 第一次匹配 我们可以看出在model的index=5的字符（规定第一个为index=0）出现不匹配 那么我们需要把model后移，再次进行匹配（移动是相对的，说把target前移或者model后移都可以的咯） 此时就出现了问题，后移多少位？ 传统算法认为后移一位，继续匹配是最稳健安全的，但是这样太过浪费时间，设target长度为n，model的长度为m，那么复杂度为O(n*m)(其实能优化成(n-m)*m) KMP算法则使model尽可能多的后移，我们看到，前面已经匹配了5个字符了，而next[4]=1，说明index=4的地方和index=0的地方是相等的。那么target与model在index=4的地方能匹配，就等同于在index=0的地方也能配对。我们此时移动了4位，这个4即5-1，已配对的长度-next[index-1] 第二次匹配 index=1时不匹配，移动index-next[index-1]即1-0=1 第三次匹配 很完美，匹配成功了 再换个例子解释下移动例2 前面匹配了6个字符ABCDAB，而最后的D未匹配，D前面的字符next[6-1]=2，6-2=4，所以model串向后移动了4个位置 换个角度来看待移动我们看例2：对于target串的指针位置，规定为i，model串的指针位置规定为j。如果使得i从0到len(target)-1，每次i++，而且只增加不减少，只对j进行各种回退，即可实现复杂度为O(n)此时i=10，j=6，不匹配。之后i不变，j=next[j-1]=2，继续匹配，i++，j++这样就相当于model串后移了6-2=4位。 算法代码代码使用golang书写 12345678910111213141516//时间复杂度为o(n)其中n为str长度func getNext(model string) []int { len := len(model) // 声明动态长度为len的一个next数组 next := make([]int, len) for i := 1; i &lt; len; i++ { // 无非归零，归一，加一三种情况 if next[i-1] &gt; 0 &amp;&amp; model[next[i-1]] == model[i] { next[i] = next[i-1] + 1 } else if model[0] == model[i] { next[i] = 1 } // 不修改表示next[i]=0 } return next} 12345678910111213141516171819202122//时间复杂度为o(m)其中m为str长度func KMP(model, target string) bool { next := getNext(model) same := 0 // 保证i始终不退回，j尽量少退回 for i, j := 0, 0; i &lt; len(target); i++ { if model[j] == target[i] { same++ j++ } else if j &gt; 0 { // 前面一位的next值表示各种回退后此时匹配的字符数 same = next[j-1] // j就回退到same的值，前j位都匹配完成了，只需要往后匹配 j = same } if same == len(model) { // 此时刚好匹配完成，开始位置为i-length+1，结束位置为i return true } } return false}","link":"/2018/01/18/kmp/"},{"title":"MarkDown数学公式","text":"在输入数学公式的时候，需要在数学公式的前后加入$$符号，将需要输入的公式加入到$$中间。 上下标 上标 ^ 下标 _ 名称 数学表达式 MarkDown公式 上标 $x^y$ $x^y$ 下标 $x_y$ $x_y$ 分数 \\frac{分子}{分母} 名称 数学表达式 MarkDown公式 分数 $\\frac{1+2x}{3y+4}$ $\\frac{1+2x}{3y+4}$ 偏微分 $\\frac{\\partial f}{\\partial x} = 2,\\sqrt{a},x$ $\\frac{\\partial f}{\\partial x} = 2\\,\\sqrt{a}\\,x$ 累加 \\sum_{下标}^{上标}{表达式} \\sum^{上标}_{下标}{表达式} 累加号的上标下标的前后顺序可以互换。 名称 数学表达式 MarkDown公式 求和 $\\sum{3x^n}$ $\\sum{3x^n}$ 范围求和1 $\\sum_{n=1}^N{3x^n}$ $\\sum_{n=1}^N{3x^n}$ 范围求和2 $\\sum_{n=1}^{2N+1}{3x^n}$ $\\sum_{n=1}^{2N+1}{3x^n}$ 累乘 \\prod_{下标}^{上标}{表达式} \\prod^{上标}_{下标}{表达式} 累加号的上标下标的前后顺序可以互换。 名称 数学表达式 MarkDown公式 累乘 $\\prod{3x^n}$ $\\prod{3x^n}$ 范围累乘1 $\\prod_{n=1}^N{3x^n}$ $\\prod_{n=1}^N{3x^n}$ 范围累乘2 $\\prod_{n=1}^{2N+1}{3x^n}$ $\\prod_{n=1}^{2N+1}{3x^n}$ 开方 \\sqrt[次方]{数值} []中写的是开几次方，{}中写的是需要开方的数值。 名称 数学表达式 MarkDown公式 开方号1 $\\sqrt[y]{x}$ $\\sqrt[y]{x}$ 开方号2 $\\sqrt[x]{y}$ $\\sqrt[x]{y}$ 开方号3 $\\sqrt[2]{a^2}$ $\\sqrt{a^2} 积分 \\int_{下标}^{上标}{表达式} 名称 数学表达式 MarkDown公式 积分 $\\int_a^b{f(x)}{\\rm d}x$ $\\int_a^b{f(x)}{\\rm d}x$ 二重积分 $\\iint_a^b{f(x)}{\\rm d}x$ $\\iint_a^b{f(x)}{\\rm d}x$ 三重积分 $\\iiint_a^b{f(x)}{\\rm d}x$ $\\iiint_a^b{f(x)}{\\rm d}x$ 正无穷、负无穷 \\infty 名称 数学表达式 MarkDown公式 正无穷 $+\\infty$ $+\\infty$ 负无穷 $-\\infty$ $-\\infty$ 极限 名称 数学表达式 MarkDown公式 左箭头 $\\lim_{n\\rightarrow+\\infty} n$ $\\lim_{n\\rightarrow+\\infty} n$ 关系运算符 名称 数学表达式 MarkDown公式 大于等于 $\\geq$ $\\geq$ 小于等于 $\\leq$ $\\leq$ 包含于 $\\subset$ $\\subset$ 包含 $\\supset$ $\\supset$ 属于 $\\in$ $\\in$ 二元运算符 名称 数学表达式 MarkDown公式 加减 $\\pm$ $\\pm$ 点乘 $\\cdot$ $\\cdot$ 乘 $\\times$ $\\times$ 除 $\\div$ $\\div$ 否定关系运算符 名称 数学表达式 MarkDown公式 不等于 $\\not=$ $\\not=$ 不小于 $\\not&lt;$ $\\not&lt;$ 不包含 $\\not\\supset$ $\\not\\supset$ 对数运算符 $\\log_{底数}{数值}$ 名称 数学表达式 MarkDown公式 对数1 $\\log_2{8}$ $\\log_2{8}$ 对数2 $\\ln{8}$ $\\ln{8}$ 对数3 $\\lg{8}$ $\\lg{8}$ 三角运算符 名称 数学表达式 MarkDown公式 垂直 $\\bot$ $\\bot$ 角 $\\angle$ $\\angle$ 角度 $30^\\circ$ $30^\\circ$ 正弦 $\\sin$ $\\sin$ 余弦 $\\cos$ $\\cos$ 正切 $\\tan$ $\\tan$ 箭头 名称 数学表达式 MarkDown公式 左箭头 $\\leftarrow$ $\\leftarrow$ 右箭头 $\\rightarrow$ $\\rightarrow$ 长箭头 $\\longrightarrow$ $\\longrightarrow$ 上箭头 $\\uparrow$ $\\uparrow$ 下箭头 $\\downarrow$ $\\downarrow$","link":"/2018/05/20/MarkDown%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/"},{"title":"NoSQL与SQL对比","text":"概念 SQL (Structured Query Language) 数据库，指关系型数据库。主要代表：SQL Server，Oracle，MySQL(开源)，PostgreSQL(开源)。NoSQL（Not Only SQL）泛指非关系型数据库。主要代表：MongoDB，Redis，CouchDB，HBase。 随着web2.0的快速发展，非关系型、分布式数据存储得到了快速的发展，它们不保证关系数据的ACID特性。NoSQL概念在2009年被提了出来。NoSQL最常见的解释是“non-relational”，“Not Only SQL”也被很多人接受。（“NoSQL”一词最早于1998年被用于一个轻量级的关系数据库的名字。） NoSQL被我们用得最多的当数key-value存储，当然还有其他的文档型的、列存储、图型数据库、xml数据库等。在NoSQL概念提出之前，这些数据库就被用于各种系统当中，但是却很少用于web互联网应用。比如cdb、qdbm、bdb数据库。 区别 存储方式 SQL数据存在特定结构的表中；而NoSQL则更加灵活和可扩展，存储方式可以省是JSON文档、哈希表或者其他方式。SQL通常以数据库表形式存储数据。举个栗子，存个学生借书数据：而NoSQL存储方式比较灵活，比如使用类JSON文件存储上表中熊大的借阅数据： 表/数据集合的数据的关系 在SQL中，必须定义好表和字段结构后才能添加数据，例如定义表的主键(primary key)，索引(index),触发器(trigger),存储过程(stored procedure)等。表结构可以在被定义之后更新，但是如果有比较大的结构变更的话就会变得比较复杂。在NoSQL中，数据可以在任何时候任何地方添加，不需要先定义表。例如下面这段代码会自动创建一个新的”借阅表”数据集合：NoSQL也可以在数据集中建立索引。以MongoDB为例，会自动在数据集合创建后创建唯一值_id字段，这样的话就可以在数据集创建后增加索引。从这点来看，NoSQL可能更加适合初始化数据还不明确或者未定的项目中。 外部数据存储 SQL中如何需要增加外部关联数据的话，规范化做法是在原表中增加一个外键，关联外部数据表。例如需要在借阅表中增加审核人信息，先建立一个审核人表：再在原来的借阅人表中增加审核人外键：这样如果我们需要更新审核人个人信息的时候只需要更新审核人表而不需要对借阅人表做更新。而在NoSQL中除了这种规范化的外部数据表做法以外，我们还能用如下的非规范化方式把外部数据直接放到原数据集中，以提高查询效率。缺点也比较明显，更新审核人数据的时候将会比较麻烦。 SQL中的JOIN查询 SQL中可以使用JOIN表链接方式将多个关系数据表中的数据用一条简单的查询语句查询出来。NoSQL暂未提供类似JOIN的查询方式对多个数据集中的数据做查询。所以大部分NoSQL使用非规范化的数据存储方式存储数据。 数据耦合性 SQL中不允许删除已经被使用的外部数据，例如审核人表中的”熊三”已经被分配给了借阅人熊大，那么在审核人表中将不允许删除熊三这条数据，以保证数据完整性。而NoSQL中则没有这种强耦合的概念，可以随时删除任何数据。 事务 SQL中如果多张表数据需要同批次被更新，即如果其中一张表更新失败的话其他表也不能更新成功。这种场景可以通过事务来控制，可以在所有命令完成后再统一提交事务。而NoSQL中没有事务这个概念，每一个数据集的操作都是原子级的。 增删改查语法 查询性能 在相同水平的系统设计的前提下，因为NoSQL中省略了JOIN查询的消耗，故理论上性能上是优于SQL的。 优缺点 关系型数据库&lt;1&gt;关系数据库的特点是： 数据关系模型基于关系模型，结构化存储，完整性约束。 基于二维表及其之间的联系，需要连接、并、交、差、除等数据操作。 采用结构化的查询语言（SQL）做数据读写。 操作需要数据的一致性，需要事务甚至是强一致性。 &lt;2&gt;优点： 保持数据的一致性（事务处理） 可以进行join等复杂查询。 通用化，技术成熟。 &lt;3&gt;缺点: 数据读写必须经过sql解析，大量数据、高并发下读写性能不足。 对数据做读写，或修改数据结构时需要加锁，影响并发操作。 无法适应非结构化存储。 扩展困难。 昂贵、复杂。 NoSQL数据库&lt;1&gt;NoSQL数据库的特点是： 非结构化的存储。 基于多维关系模型。 具有特有的使用场景。 &lt;2&gt;优点： 高并发，大数据下读写能力较强。 基本支持分布式，易于扩展，可伸缩。 简单，弱结构化存储。 &lt;3&gt;缺点: join等复杂操作能力较弱。 事务支持较弱。 通用性差。 无完整约束复杂业务场景支持较差。 补充 目前许多大型互联网项目都会选用MySQL（或任何关系型数据库） + NoSQL的组合方案。 关系型数据库适合存储结构化数据，如用户的帐号、地址： 1）这些数据通常需要做结构化查询（嗯，好像是废话），比如join，这时候，关系型数据库就要胜出一筹 2）这些数据的规模、增长的速度通常是可以预期的 3）事务性、一致性 NoSQL适合存储非结构化数据，如文章、评论： 1）这些数据通常用于模糊处理，如全文搜索、机器学习 2）这些数据是海量的，而且增长的速度是难以预期的， 3）根据数据的特点，NoSQL数据库通常具有无限（至少接近）伸缩性 4）按key获取数据效率很高，但是对join或其他结构化查询的支持就比较差 基于它们的适用范围不同，目前主流架构才会采用组合方案，一个也不能少。目前为止，还没有出现一个能够通吃各种场景的数据库，而且根据CAP理论，这样的数据库是不存在的。","link":"/2018/01/02/SQL%E5%92%8CNOSQL/"},{"title":"manacher算法","text":"原题再现LeetCode problem No.5 Given a string s, find the longest palindromic substring in s. You may assume that the maximum length of s is 1000.从字符串s中找出最长的回文子串，s的长度不会超过1000 Example:Input: “babad”Output: “bab”Note: “aba” is also a valid answer. Example:Input: “cbbd”Output: “bb” 通俗解法1234567891011121314151617181920212223242526272829303132func longestPalindrome(str string) string { start, end, len1, len2, lenPalindrome := 0, 0, 0, 0, 0 for i := 0; i &lt; len(str); i++ { // 奇偶要分开讨论 len1 = palindromeLen(str, i, i) len2 = palindromeLen(str, i, i+1) lenPalindrome = maxInt(len1, len2) if lenPalindrome &gt; end-start { start, end = i-(lenPalindrome-1)/2, i+lenPalindrome/2 } } return str[start:end+1]}// golang中没有max，min这类函数，自己写一个func maxInt(a, b int) int { if a &gt; b { return a } else { return b }}func palindromeLen(str string, left, right int) int { i := 0 for i = 0; left-i &gt;= 0 &amp;&amp; right+i &lt; len(str); i++ { if str[left-i] != str[right+i] { break } } return 2*i - 1 + right - left} 启发思考受到之前kmp算法的提示，我们应该能感受到，这种字符串找规律的题目，应该会有更加操作简便的解法。 分开讨论的部分能不能一起讨论？ 能不能整理出一个类似kmp的next数组的规律数组？ 能不能以线性的复杂度搞定？ 介绍 马拉车算法Manacher’s Algorithm是用来查找一个字符串的最长回文子串的线性方法，由Manacher在1975年发明的，这个方法的最大贡献是在于将时间复杂度提升到了线性。 这个算法解决了奇偶分开讨论的问题，把冗余的循环节省掉，将时间复杂度降低到O(n) 原理LeetCode马拉车讲解（英文版），这个推荐看一下，写的很棒。 改造字符串123source = a b c a c b a d fstrNew = $ # a # b # c # a # c # b # a # d # f # &amp;prGroup[i]= 0 0 1 0 1 0 1 0 7 0 1 0 1 0 1 0 1 0 1 0 0 123source = a b a a b astrNew = $ # a # b # a # a # b # a # &amp;prGroup[i]= 0 0 1 0 3 0 1 6 1 0 3 0 1 0 0 每个字符中间都加上#，首尾也加上。为了防止字符串越界，首尾再增加一个不同的字符。prGroup[i]是指以i为下标的字符，它的回文长度（去掉字符本身）palindrome-group 规律数组 例如上图，我们已经知道了i=13以前所有的prprGroup，那么i=13时还需要再次一遍遍的往两侧循环检测吗？当然不需要，不然复杂度又成O(n^2)了 我们选取目前已知的，能够使右边界R的index最大的prGroup，此时R=20，L=2，C=11之后需要对不同的i进行判断 当 i &lt;= R 时： 若有 prGroup[i’] &lt; R-i 我们已经知道了C=11处是对称点，如果C左侧的某个点的prGroup长度能够保证在[L,C]区间内，那么对称点必然相同。i=13时，有 prGroup[i’]==prGroup[i] prGroup[i’] &gt;= R-i 那么此时的情况呢？当然不在保证 prGroup[i’]==prGroup[i] 一定成立，因为从R之后的点都是未知的，但可以保证 prGroup[i] &gt;= R-i。例如下图，i=15时，prGroup[i’]已经超出[L,C]区间，有prGroup[i]&gt;= R-i，R之后的字符是否符合需要一步一步往后验证，并更新R，L，C 当 i &gt; R 时，已经超过[L,R]区间，只能往后一个一个的验证，直至更新R，L，C 代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// 著名的马拉车算法，将复杂度回归线性O(n)func manacher(source string) string { // 先对字符串增加#字符 str := changeStr(source) lenStr := len(str) prGroup := make([]int, lenStr) tempCentre, tempRight, prMax, prMaxIndex := 0, 0, 0, 1 for i := 1; i &lt; len(str)-1; i++ { // golang没有三元运算符 if i &lt;= tempRight { prGroup[i] = minInt(tempRight-i, prGroup[2*tempCentre-i]) } else { prGroup[i] = 0 } for str[i-prGroup[i]-1] == str[i+prGroup[i]+1] { prGroup[i]++ } if tempRight &lt; prGroup[i]+i { tempCentre = i tempRight = i + prGroup[i] } if prMax &lt; prGroup[i] { prMax = prGroup[i] prMaxIndex = i } } return source[(prMaxIndex-1-prMax)/2:(prMaxIndex-1+prMax)/2]}func minInt(a, b int) int { if a &gt; b { return b } else { return a }}func changeStr(source string) string { b := bytes.Buffer{} b.WriteString(&quot;$#&quot;) for i := 0; i &lt; len(source); i++ { b.WriteString(string(source[i])) b.WriteString(&quot;#&quot;) } b.WriteString(&quot;&amp;&quot;) return b.String()}","link":"/2018/01/26/manacher/"},{"title":"在树莓派上搭建软路由","text":"出发点 很早的时候一直在用网件 wndr4300 刷了 openwrt 以及 lede 这种开放式的路由系统，一直沉迷于无界浏览无法自拔。因为笔者最近在学习的一些东西比较新，在国内看不到详细的文档，能上 google 当然是最好的。 要求提升 当然不能满足于可以访问，作为一个年轻人就要有敢于折腾的精神。速度慢点的路由已经满足不了笔者的需求了。刚好前几天买了个树莓派3，不折腾下似乎有点过分了啊。 准备工具需要的设备 电脑一台 树莓派 or 其他linux平台 网卡2个，有线，无线，usb网卡都行 网线一根 需要的软件 dnsmasq or isc-dhcp-server overture or DNScrypt v2ray shadowsocks or shadowsocks-rss 网络拓扑 开始动手配置网卡 先把提供本机dhcp服务的网卡地址配置好，给自己赋予一个静态地址 123456789101112131415sudo vim /etc/network/interfaces# 加入以下内容auto loiface lo inet loopbackauto eth0allow-hotplug eth0iface eth0 inet dhcpauto eth1allow-hotplug eth1iface eth1 inet static address 192.168.20.1 network 192.168.20.0 netmask 255.255.255.0 broadcast 192.168.20.255 解释下eth0和eth1是我的树莓派上两张网卡，这个网卡名字不一定都是这种，根据自己的网卡名称进行修改，输入ifconfig来查看 eth0是连接上级路由的，它的网段是192.168.10.0，我直接连上就能上网了，把这张卡设置dhcp，自动从上级路由获取ip，如果是无线网卡一般是wlan0 eth1是本机用来提供路由服务的，设置自己的网段，并且赋予自己固定ip 配置 dnsmasq 首先安装 dnsmasq 来提供 dhcp 和 dns 缓存服务 12345sudo apt-get install dnsmasq# 安装完成后查看安装状态pi@raspberrypi:~ $ dnsmasq -vDnsmasq version 2.76 Copyright (c) 2000-2016 Simon KelleyCompile time options: IPv6 GNU-getopt DBus i18n IDN DHCP DHCPv6 no-Lua TFTP conntrack ipset auth DNSSEC loop-detect inotify 编辑 dnsmasq 配置文件 12345678910111213141516171819# 不需要提供dhcp服务的网卡，一般是连接外网的那张卡no-dhcp-interface=eth0dhcp-range=192.168.20.10,192.168.20.100,72hcache-size=102400log-facility=/var/log/dnsmasq/dnsmasq.log# 指定返回给客户端的ttl时间，一般不需要设置max-ttl=28800# 本地 hosts 文件的缓存时间，通常不要求缓存本地，这样更改hosts文件后就即时生效。local-ttl=360# 对于上游返回的值没有ttl时，dnsmasq给一个默认的ttl，一般不需要设置neg-ttl=28800# 设置在缓存中的条目的最大 TTL。max-cache-ttl=28800# 设置在缓存中的条目的最小 TTL。min-cache-ttl=10800conf-dir=/etc/dnsmasq.d/ 如果你是使用了isc-dhcp-server这种额外的 dhcp 服务器，那么就把上面 12no-dhcp-interface=eth0dhcp-range=192.168.20.10,192.168.20.100,72h 这两句删掉吧，如果不设定dhcp-range dnsmasq 默认是不开启 dhcp 的，然后这么配置isc-dhcp-server 123456789101112131415161718192021sudo vim /etc/dhcp/dhcpd.conf# 添加以下内容ddns-update-style none;default-lease-time 600;max-lease-time 7200;# 网段subnet 192.168.20.0 netmask 255.255.255.0 { # DHCP 分配ip范围 range 192.168.20.10 192.168.20.100; # DHCP 给接入设备分配的网关 option routers 192.168.20.1; option subnet-mask 255.255.255.0; option broadcast-address 192.168.20.255; # 分配的DNS服务器 option domain-name-servers 192.168.20.1;} 建议直接用 dnsmasq 好了，忽略上面两条内容即可 添加 gfwlist 123456cd git clone https://github.com/cokebar/gfwlist2dnsmasq.gitcd gfwlist2dnsmasqchmod a+x gfwlist2dnsmasq.sh./gfwlist2dnsmasq -o gfwlist.conf -s gfwlistsudo cp gfwlist.conf /etc/dnsmasq.d/ 在gfwlist.conf中都是这样的存在 12345server=/030buy.com/127.0.0.1#5300ipset=/030buy.com/gfwlistserver=/0rz.tw/127.0.0.1#5300ipset=/0rz.tw/gfwlist... 127.0.0.1#5300代表匹配的域名通过这个服务器和端口进行 DNS 解析，而这个端口是多少取决于一会你的防污染 DNS 服务器开启的端口，刚生成的是 5353 端口，我的因为被占用了，查找并替换改成 5300 12345# 开启dnsmasqsudo service dnsmasq start# 设置开机自启动sudo systemctl enable dnsmasq 配置转发服务1234567sudo vim /etc/sysctl.conf# 修改一项，把前面注释号#去掉，或者自己加net.ipv4.ip_forward = 1# 让上述修改立刻生效sysctl -p iptables开启网段定向转发 1234567sudo iptables -t nat -A POSTROUTING -s 192.168.20.0/24 -o eth0 -j MASQUERADE# 上面这条命令重启就没了，写入文件中保证长期有效sudo vim /etc/rc.local# 在 exit0 前加入iptables -t nat -A POSTROUTING -s 192.168.20.0/24 -o eth0 -j MASQUERADE ok， 至此，一个具有正常功能的普通路由就可以使用了，连接的设备也是可以上网的了 配置无污染的上级 DNS 其实多此一举，v2ray 自带无污染dns服务 安装 overture, 去 github 下载 release-binary, 我的树莓派下载 overture-linux-arm.zip 修改配置文件 config.json 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748{ &quot;BindAddress&quot;: &quot;:5300&quot;, &quot;PrimaryDNS&quot;: [ { &quot;Name&quot;: &quot;DNSPod&quot;, &quot;Address&quot;: &quot;119.29.29.29:53&quot;, &quot;Protocol&quot;: &quot;udp&quot;, &quot;SOCKS5Address&quot;: &quot;&quot;, &quot;Timeout&quot;: 6, &quot;EDNSClientSubnet&quot;: { &quot;Policy&quot;: &quot;disable&quot;, &quot;ExternalIP&quot;: &quot;&quot; } }, { &quot;Name&quot;: &quot;114&quot;, &quot;Address&quot;: &quot;114.114.114.114:53&quot;, &quot;Protocol&quot;: &quot;udp&quot;, &quot;Timeout&quot;: 6, &quot;EDNSClientSubnet&quot;: { &quot;Policy&quot;: &quot;disable&quot;, &quot;ExternalIP&quot;: &quot;&quot; } } ], &quot;AlternativeDNS&quot;: [ { &quot;Name&quot;: &quot;OpenDNS&quot;, &quot;Address&quot;: &quot;208.67.222.222:443&quot;, &quot;Protocol&quot;: &quot;tcp&quot;, &quot;SOCKS5Address&quot;: &quot;&quot;, &quot;Timeout&quot;: 6, &quot;EDNSClientSubnet&quot;: { &quot;Policy&quot;: &quot;disable&quot;, &quot;ExternalIP&quot;: &quot;&quot; } } ], &quot;OnlyPrimaryDNS&quot;: false, &quot;RedirectIPv6Record&quot;: true, &quot;IPNetworkFile&quot;: &quot;./ip_network_sample&quot;, &quot;DomainFile&quot;: &quot;./domain_sample&quot;, &quot;DomainBase64Decode&quot;: true, &quot;HostsFile&quot;: &quot;./hosts_sample&quot;, &quot;MinimumTTL&quot;: 0, &quot;CacheSize&quot; : 0, &quot;RejectQtype&quot;: [255]} 然后直接运行就行 ./overture-linux-arm, 这样不能关闭这次连接的终端，否则就关闭了，可以选择开一个 screen 来运行，或者./overture-linux-arm &amp; DNSCrypt 可以代替 overture 不过配置麻烦，读者可以自行研究，功能更加强大稳定 配置 v2ray 先去安装 v2ray 1234cd wget https://install.direct/go.shsudo bash go.shsudo vim /etc/v2ray/config.json 客户端配置出一个socks5代理端口 8080 (以备不时之需)、一个透明代理端口 1080 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687{ &quot;log&quot;: { &quot;access&quot;: &quot;/var/log/v2ray/access.log&quot;, &quot;error&quot;: &quot;/var/log/v2ray/error.log&quot;, &quot;loglevel&quot;: &quot;warning&quot; }, &quot;inbound&quot;: { &quot;port&quot;: 8080, &quot;listen&quot;: &quot;192.168.20.1&quot;, &quot;protocol&quot;: &quot;socks&quot;, &quot;settings&quot;: { &quot;auth&quot;: &quot;noauth&quot;, &quot;udp&quot;: false } }, &quot;inboundDetour&quot;: [ { &quot;protocol&quot;: &quot;dokodemo-door&quot;, &quot;port&quot;:1080, &quot;settings&quot;:{ &quot;network&quot;: &quot;tcp,udp&quot;, &quot;timeout&quot;: 30, &quot;followRedirect&quot;: true } }, { &quot;protocol&quot;: &quot;dokodemo-door&quot;, &quot;port&quot;:5300, &quot;settings&quot;:{ &quot;address&quot;:&quot;8.8.8.8&quot;, &quot;port&quot;:53, &quot;network&quot;: &quot;udp&quot;, &quot;timeout&quot;: 30, &quot;followRedirect&quot;: false } } ], &quot;outbound&quot;: { &quot;protocol&quot;: &quot;vmess&quot;, &quot;settings&quot;: { &quot;vnext&quot;: [ { &quot;address&quot;: &quot;yourserver.com&quot;, &quot;port&quot;: 12345, &quot;users&quot;: [ { &quot;id&quot;: &quot;1sb4165e-1234-4310-9d57-a8a2994r5e0d&quot;, &quot;alterId&quot;: 32, &quot;security&quot;: &quot;auto&quot; } ] } ] }, &quot;streamSettings&quot;:{ &quot;network&quot;:&quot;kcp&quot;, &quot;kcpSettings&quot;: { &quot;mtu&quot;: 1350, &quot;tti&quot;: 20, &quot;uplinkCapacity&quot;: 5, &quot;downlinkCapacity&quot;: 100, &quot;congestion&quot;: false, &quot;readBufferSize&quot;: 1, &quot;writeBufferSize&quot;: 1, &quot;header&quot;: { &quot;type&quot;: &quot;none&quot; } } }, &quot;mux&quot;: { &quot;enabled&quot;: true } }, &quot;outboundDetour&quot;: [ { &quot;protocol&quot;: &quot;freedom&quot;, &quot;settings&quot;: {}, &quot;tag&quot;: &quot;direct&quot; } ], &quot;dns&quot;: { &quot;servers&quot;: [ &quot;8.8.8.8&quot;, &quot;localhost&quot; ] }} iptables 和 ipset 设置 123456789101112sudo apt-get install ipsetsudo ipset -N gfwlist iphashsudo iptables -t nat -A PREROUTING -p tcp -m set --match-set gfwlist dst -j REDIRECT --to-port 1080sudo iptables -t nat -A OUTPUT -p tcp -m set --match-set gfwlist dst -j REDIRECT --to-port 1080# 把路由配置写入文件中，长久保存sudo vim /etc/rc.local# 在exit0前把这三句加上ipset -N gfwlist iphashiptables -t nat -A PREROUTING -p tcp -m set --match-set gfwlist dst -j REDIRECT --to-port 1080iptables -t nat -A OUTPUT -p tcp -m set --match-set gfwlist dst -j REDIRECT --to-port 1080 开启无限制的世界 1234sudo service v2ray start# 把 v2ray 设置为开机自启动sudo systemctl enable v2ray 效果展示 123456789101112131415161718housirvipdeiMac:~ housirvip$ dig www.google.com; &lt;&lt;&gt;&gt; DiG 9.8.3-P1 &lt;&lt;&gt;&gt; www.google.com;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 23438;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 0;; QUESTION SECTION:;www.google.com. IN A;; ANSWER SECTION:www.google.com. 1978 IN A 172.217.26.36;; Query time: 17 msec;; SERVER: 192.168.20.1#53(192.168.20.1);; WHEN: Thu Aug 17 23:59:10 2017;; MSG SIZE rcvd: 48","link":"/2017/08/16/soft-router/"},{"title":"编译安装 shadowsocksr-libev","text":"起因作为一个开发者，不能上 google 是有多难受，吃灰的树莓派刚好派上了用场 安装准备工具 电脑一台 树莓派 ssr 账号一个 ssr-libev 源码 各种依赖 开始动手安装开发环境1sudo apt-get install git build-essential cmake -y 一般的 ubuntu 和 debian 系统都可以做到，但是我之前用的 ubuntu mate 会报错，找不到 build-essential，那么使用 aptitude 来解决依赖项 12sudo apt-get install aptitude -ysudo aptitude install build-essential -y 安装依赖项 这里列举下一般容易缺少的依赖项 libssl libsodium libpcre 这些依赖项可以去选择手动编译，也可以直接 1sudo apt-get install -y libsodium-dev libpcre3 libpcre3-dev libssl-dev 开始编译 ssr123456cdgit clone https://github.com/shadowsocksr-backup/shadowsocksr-libev.gitcd shadowsocksr-libevsudo ./configure --prefix=/usr/local/shadowsocksR --disable-documentationsudo make -j4sudo make install 使用 ssr12sudo mkdir /usr/local/shadowsocksR/confsudo vi config.json 加入以下内容，并根据自己的服务器进行正确修改 12345678910111213{ &quot;server&quot;:&quot;your server address here&quot;, &quot;server_port&quot;:1234, &quot;local_port&quot;:1080, &quot;password&quot;:&quot;your password here&quot;, &quot;timeout&quot;:600, &quot;method&quot;:&quot;chacha20&quot;, &quot;protocol&quot;:&quot;auth_aes128_md5&quot;, &quot;obfs&quot;:&quot;tls1.2_ticket_auth&quot;, &quot;obfsparam&quot;:&quot;&quot; , &quot;group&quot;:&quot;any you like&quot;, &quot;local_address&quot;:&quot;0.0.0.0&quot;,} 启动 ssr 1234567891011/usr/local/shadowsocksR/bin/ss-local -c /usr/local/shadowsocksR/conf/config.jsonpi@raspberrypi:~ $ /usr/local/shadowsocksR/bin/ss-local -c /usr/local/shadowsocksR/conf/sg.json 2017-08-24 04:44:55 INFO: protocol auth_aes128_md5 2017-08-24 04:44:55 INFO: protocol_param (null) 2017-08-24 04:44:55 INFO: method chacha20 2017-08-24 04:44:55 INFO: obfs tls1.2_ticket_auth 2017-08-24 04:44:55 INFO: obfs_param (null) 2017-08-24 04:44:56 INFO: initializing ciphers... chacha20 2017-08-24 04:44:56 INFO: tcp port reuse enabled 2017-08-24 04:44:56 INFO: listening at 0.0.0.0:1080 可以配置 supervisor 守护进程 测试 完善 利用 ss-redir 全局透明代理 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152cd# 获取大陆ip地址段curl -sL http://f.ip.cn/rt/chnroutes.txt | egrep -v '^$|^#' &gt; chnroutes# ipsetsudo apt-get -y install ipsetsudo ipset -N chnroutes hash:netfor i in `cat chnroutes`; do echo ipset -A chnroutes $i &gt;&gt; ipset.sh; donechmod +x ipset.sh &amp;&amp; ./ipset.sh# 持久化 ipset 地址列表至文件sudo ipset save chnroutes &gt; ~/chnroutes.ipset# 从文件恢复到 ipsetsudo ipset destroy chnroutessudo ipset restore &lt; ~/chnroutes.ipset# 新建一条链 shadowsockssudo iptables -t nat -N shadowsocks# 保留地址、私有地址、回环地址 不走代理sudo iptables -t nat -A shadowsocks -d 0.0.0.0/8 -j RETURNsudo iptables -t nat -A shadowsocks -d 10.0.0.0/8 -j RETURNsudo iptables -t nat -A shadowsocks -d 127.0.0.0/8 -j RETURNsudo iptables -t nat -A shadowsocks -d 169.254.0.0/16 -j RETURNsudo iptables -t nat -A shadowsocks -d 172.16.0.0/12 -j RETURNsudo iptables -t nat -A shadowsocks -d 192.168.0.0/16 -j RETURNsudo iptables -t nat -A shadowsocks -d 224.0.0.0/4 -j RETURNsudo iptables -t nat -A shadowsocks -d 240.0.0.0/4 -j RETURN# 1234 是 ss 代理服务器的端口，即远程 shadowsocks 服务器提供服务的端口# 如果你有多个 ip 可用,但端口一致，就设置这个sudo iptables -t nat -A shadowsocks -p tcp --dport 1234 -j RETURN# your_server 是 ss 代理服务器的 ip# 如果你只有一个 ss 服务器的 ip，却能选择不同端口,就设置此条sudo iptables -t nat -A shadowsocks -d your_server -j RETURN# 大陆地址不走代理sudo iptables -t nat -A shadowsocks -m set --match-set chnroutes dst -j RETURN# 其余的全部重定向至 ss-redir 监听端口sudo iptables -t nat -A shadowsocks -p tcp -j REDIRECT --to-ports 1080# OUTPUT 和 PREROUTING 链添加一条规则，重定向至 shadowsocks 链sudo iptables -t nat -A OUTPUT -p tcp -j shadowsockssudo iptables -t nat -I PREROUTING -p tcp -j shadowsocks# 持久化 iptables 规则到文件sudo iptables-save &gt; ~/iptables.shadowsocks# 从文件恢复到 iptablessudo iptables-restore &lt; ~/iptables.shadowsocks","link":"/2017/08/24/ssr-install/"},{"title":"高并发web系统设计","text":"核心技术点 前端优化 前端优化主要包括动态内容静态化，增加前端缓存。页面静态化是指将指含有大量动态元素的动态网页，如jsp、php等，转换为html静态页面，静态页面由于不用加载动态元素，其访问速度要比动态页面快得多，可以增加访问速度，减小数据库压力；前端页面缓存在系统前端对Web服务器上的页面进行缓存。 CDN技术 CDN即内容分发网络，其基本思路是尽可能避开互联网上有可能影响数据传输速度和稳定性的瓶颈和环节，使内容传输的更快、更稳定。通过在网络各处放置节点服务器所构成的在现有的互联网基础之上的一层智能虚拟网络，CDN系统能够实时地根据网络流量和各节点的连接、负载状况以及到用户的距离和响应时间等综合信息将用户的请求重新导向离用户最近的服务节点上。其目的是使用户可就近取得所需内容，解决 Internet网络拥挤的状况，提高用户访问网站的响应速度。 负载均衡 负载均衡的基本思想是把高并发的访问平均分配到每一个服务器节点上，从而减小分布式数据库中每一个节点的压力。 中间件 数据库的中间件技术是指把应用层与数据库层分离，在中间增加一个部分，避免应用直接访问数据库。因为系统可能采用读写分离的技术，因而会使用不同的数据库，中间件可以屏蔽数据库直接的不同，提供统一的接口。中间件还负责事务的协调处理，起到数据连接管理的作用，多个客户端连接通过中间件可以共用一个数据库连接。 memcached memcached是一个高性能的分布式内存对象缓存系统，通过在内存中缓存数据和对象来减少读取数据库的次数，从而提高动态、数据库驱动网站的速度，它是基于一个存储键/值对的hashmap。 并发控制 数据库限流，达到数据库的最大并发数，进入行锁状态。如不进行控制，一旦其中一个连接卡住，会引发雪崩效应，从而影响整个系统 排队系统 锁机制导致排队 并行复制 采用并行复制的技术可以解决主备库复制延迟问题 数据库拆分 分为水平拆分和垂直拆分，垂直拆分即按列拆分，把数据按应用分离，降低单个事务的数据处理量；水平拆分即按行拆分，降低节点的并发量 读写分离 有些系统读操作频繁，而有些系统写操作频繁，读写分离能有效提高访问速度 高并发带来的问题和解决方案事务问题（一致性） 容器事务管理 锁机制 隔离机制 状态问题(session) 用cooke记录sesion 缺点是有大小限制，另外不稳定，客户端可能关闭浏览器导致数据丢失，且不安全 session复制 即集群中的服务器都持有一份sesion，每次有数据变化时需要同步给其他服务器，适合小规模网站 session绑定 由负载均衡服务器将客户的IP/cookie与session绑定，实现会话粘滞。但这种方案缺乏高可用性，因为客户的关闭浏览器可能会改变cookie，客户端IP也可能变化，服务器端也可能宕机导致session丢失。 session服务器 包含两个层面，一个是利用分布式缓存，可以实现会话的保持，适合一般集群需求另一个是独立session服务器，适合更高要求的需求，例如单点登录（SSO） 设计原则 墨菲定律 任何事没有表面看起来那么简单 - 所有的事都会比预计的时间长 - 可能出错的事情总会出错 - 担心某种事情发生，那么它就更有可能发生 康威定律 系统架构师公司组织架构的反映 - 按照业务闭环进行系统拆分/组织架构划分，实现闭环、高内聚、低耦合，减少沟通成本 - 如果沟通出现问题，应该考虑进行系统和组织架构的调整 - 适合时机进行系统拆分，不要一开始就吧系统、服务拆分拆的非常细，虽然闭环，但是每个人维护的系统多，维护成本高 - 微服务架构的理论基础 - 康威定律 二八定律 80%的结果取决于20%的原因 高并发原则 无状态 无状态应用，便于水平扩展有状态配置可通过配置中心实现无状态 拆分 系统维度：按照系统功能、业务拆分，如购物车，结算，订单等功能维度：对系统功能在做细粒度拆分读写维度：根据读写比例特征拆分；读多，可考虑多级缓存；写多，可考虑分库分表AOP维度： 根据访问特征，按照AOP进行拆分，比如商品详情页可分为CDN、页面渲染系统，CDN就是一个AOP系统模块维度：对整体代码结构划分Web、Service、DAO 服务化 服务化演进: 进程内服务-单机远程服务-集群手动注册服务-自动注册和发现服务-服务的分组、隔离、路由-服务治理考虑服务分组、隔离、限流、黑白名单、超时、重试机制、路由、故障补偿等 消息队列 目的: 服务解耦(一对多消费)、异步处理、流量削峰缓冲等大流量缓冲： 牺牲强一致性，保证最终一致性(案例：库存扣减，现在Redis中做扣减，记录扣减日志，通过后台进程将扣减日志应用到DB)数据校对: 解决异步消息机制下消息丢失问题 数据异构 数据异构: 通过消息队列机制接收数据变更，原子化存储数据闭环: 屏蔽多从数据来源，将数据异构存储，形成闭环 缓存银弹 并发化 高可用原则 降级 降级开关集中化管理：将开关配置信息推送到各个应用可降级的多级读服务：如服务调用降级为只读本地缓存开关前置化：如Nginx+lua(OpenResty)配置降级策略，引流流量；可基于此做灰度策略业务降级：高并发下，保证核心功能，次要功能可由同步改为异步策略或屏蔽功能 限流 目的: 防止恶意请求攻击或超出系统峰值实践：恶意请求流量只访问到Cache穿透后端应用的流量使用Nginx的limit处理恶意IP使用Nginx Deny策略或者iptables拒绝 切流量 目的：屏蔽故障机器实践:DNS: 更改域名解析入口，如DNSPOD可以添加备用IP，正常IP故障时，会自主切换到备用地址;生效实践较慢HttpDNS: 为了绕过运营商LocalDNS实现的精准流量调度LVS/HaProxy/Nginx: 摘除故障节点 可回滚 发布版本失败时可随时快速回退到上一个稳定版本 业务设计原则 防重设计 幂等设计 流程定义 状态与状态机 后台系统操作可反馈 后台系统审批化 文档注释 备份","link":"/2018/01/02/%E9%AB%98%E5%B9%B6%E5%8F%91web%E8%AE%BE%E8%AE%A1/"}],"tags":[{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"Web","slug":"Web","link":"/tags/Web/"},{"name":"Consul","slug":"Consul","link":"/tags/Consul/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"MarkDown","slug":"MarkDown","link":"/tags/MarkDown/"},{"name":"Math","slug":"Math","link":"/tags/Math/"},{"name":"数据库","slug":"数据库","link":"/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"Dns","slug":"Dns","link":"/tags/Dns/"},{"name":"树莓派","slug":"树莓派","link":"/tags/%E6%A0%91%E8%8E%93%E6%B4%BE/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"设计模式","slug":"设计模式","link":"/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"黑苹果","slug":"黑苹果","link":"/tags/%E9%BB%91%E8%8B%B9%E6%9E%9C/"},{"name":"Hackintosh","slug":"Hackintosh","link":"/tags/Hackintosh/"},{"name":"面经","slug":"面经","link":"/tags/%E9%9D%A2%E7%BB%8F/"},{"name":"算法","slug":"算法","link":"/tags/%E7%AE%97%E6%B3%95/"},{"name":"LeetCode","slug":"LeetCode","link":"/tags/LeetCode/"},{"name":"Golang","slug":"Golang","link":"/tags/Golang/"},{"name":"pve","slug":"pve","link":"/tags/pve/"},{"name":"分布式","slug":"分布式","link":"/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"软路由","slug":"软路由","link":"/tags/%E8%BD%AF%E8%B7%AF%E7%94%B1/"},{"name":"Openwrt","slug":"Openwrt","link":"/tags/Openwrt/"},{"name":"SSR","slug":"SSR","link":"/tags/SSR/"},{"name":"高并发","slug":"高并发","link":"/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/"}],"categories":[],"pages":[{"title":"about","text":"笔者通常用个人博客来记录一些技术或者其他 方便在之后再次使用时可以进行查阅 毕竟好记性不如烂笔头 We’d be playing in the sand Holding hands just one last chance No more hurts no more goodbyes We’d dance We’re never going back Never turning back","link":"/about/index.html"}]}